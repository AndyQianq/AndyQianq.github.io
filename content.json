{"meta":{"title":"Celia‘s blog","subtitle":"C’est la vie","description":null,"author":"Celia Qian","url":"http://AndyQianq.github.io"},"pages":[{"title":"About","date":"2018-03-13T18:11:21.718Z","updated":"2018-03-13T18:11:21.718Z","comments":true,"path":"about.html","permalink":"http://AndyQianq.github.io/about.html","excerpt":"","text":"个人简介（About Me） 生活： 计算机专业大三狗 英文名：Celia 二次元混迹者 性别：妹子 出生年月：98年的摩羯 爱好：画画&amp;音乐 最喜欢的歌手： Eason&amp;Taylor 舔颜：さとう たける（Satoh Takeru） 喜欢物理大于喜欢数学 二次元： 圈名：檀樱 昵称：檀樱樱、樱樱、樱桃 工种：后期&amp;美工 社团： 月聆风裳 作品: 作品链接 属性：是个声控的同时又是一个取名废 名字的由来：大二的时候入圈，想着取一个什么名字好，就瞅见了桌子上的《人间词话》，然后随便翻了一页，嗯，然后嗯，随便挑了个词。。。。过了半年才想起了：啊。。。这个词是出自于“润玉笼绡，檀樱倚扇，绣圈犹带脂香浅。”，啊，这个好像不是很符合自己的糙汉属性哈。。。换一个？换啥呢。。。。 联系方式（Contacts） 生活： 邮箱：only@celiay.com； 如果您可以找到我 二次元接新： QQ: 3241412823; SinaWeibo: @檀no樱； Missevan： 檀no樱； 网易云音乐：檀樱的画； 邮箱：mail@celiay.com；剧本请发送到此邮箱，点击发送 补充几点说明 QQ用来混二次元的，不是约单请勿打扰，约单请先QQ邮箱发送剧本，会视剧本的质量考虑接新。 所有接新全看是否感兴趣和时间是否充足，而且无偿。 微博私信一般不看，邮箱每晚会翻一下，如果收到剧本后我回复了，可以申请加QQ，加好友时请说明你的圈名、工种和剧组的名称，否则不会加。 我听歌比较杂，如果你也是后期的话，可以看看我在网易云创建的歌单，希望对您有帮助。 关于本站（About Blog）为什么开博客 之前在其他的平台写过东西，像知乎，新浪博客。知乎给我的印象不错，可惜看的多了，觉得知乎确实是一个开拓自己眼界的地方但是却不能安安心心的拥有一个属于自己的空间。而新浪就更是一个杂乱的地方，并且广告的植入太多，体验感极差。 基于以上的缘由，在2017年的12月就有了写自己的博客的想法。觉得在网络空间中有一个完完整整属于自己的地方。这里可以分享我喜欢的电影、书，可以上传自己做过的项目，可以写一些随笔。想一想都觉得这是一件很酷的事情，不是吗？ 开博客做什么 记录生活 爱生活，体会生活，记录自己的生活。 写东西对于我本人而言是一种思辨的过程。 寻找自己 用来分享生活。 记录大学期间的课业工作。 补充 如果您对我的blog感兴趣，欢迎来浏览、评论。 如果您也有blog，也欢迎您提供您的blog链接。点击此处观看如何申请友链 如果您也想搭建这样的blog，可以观看具体信息。点击自处开启 本站时间function secondToDate(second){if(!second){return 0}var time=new Array(0,0,0,0,0);if(second>=365*24*3600){time[0]=parseInt(second/(365*24*3600));second%=365*24*3600}if(second>=24*3600){time[1]=parseInt(second/(24*3600));second%=24*3600}if(second>=3600){time[2]=parseInt(second/3600);second%=3600}if(second>=60){time[3]=parseInt(second/60);second%=60}if(second>0){time[4]=second}return time};function setTime(){var create_time=Math.round(new Date(Date.UTC(2018,01,15,20,14,19)).getTime()/1000);var timestamp=Math.round((new Date().getTime()+8*60*60*1000)/1000);currentTime=secondToDate((timestamp-create_time));currentTimeHtml=currentTime[0]+'年'+currentTime[1]+'天'+currentTime[2]+'时'+currentTime[3]+'分'+currentTime[4]+'秒';document.getElementById(\"htmer_time\").innerHTML=currentTimeHtml}setInterval(setTime,1000); 本站已运行 感谢您观看到最后"},{"title":"友链申请","date":"2018-02-19T06:35:46.000Z","updated":"2018-02-25T17:58:31.905Z","comments":true,"path":"apply-for-links.html","permalink":"http://AndyQianq.github.io/apply-for-links.html","excerpt":"","text":"想来互换友链的需满足以下规则： 1.站点已平稳运行超过 60 天,并有长期运行的打算（一年以上）2.原创，内容不限3.二次元小伙伴加分4.可以在 6s 之内加载完毕并正常浏览符合条件的，可以直接在博客下面评论提交申请互换友链，或者访问 Resume 找到我的联系方式直接向我申请(如果您能找得到我的话)。 请在评论里留下您的友链信息： 请务必按照格式。 Name: Link: Slogan: Description: Avatar: Favicon: Slogan 非必需；Description 尽量简短。头像或 ICON 请提供高清图片下载链接。 如果您的站点信息有改动，请更新后尽快联系我更新友链信息。"},{"title":"Reference","date":"2018-02-23T13:16:53.814Z","updated":"2018-02-23T11:41:53.675Z","comments":true,"path":"blog.html","permalink":"http://AndyQianq.github.io/blog.html","excerpt":"","text":"如何搭建关于hexo 配置环境 hexo官网链接 hexo的指令 为什么使用hexo 关于主题 material hexo如何更改主题 关于GitHub 如何部署到GitHub 关于配置 评论系统采用来比力，各位可以使用QQ，微博，微信等登陆评论即可。 使用百度在线生成二维码，电脑端的可以点击每篇文章的右上角的第一个按钮即可生成二维码，手机扫描即可阅读。（虽然我本人觉得没有什么卵用。。。。） 分享文章可以点击每篇文章的右上角的分享按钮，不过对于手机端的不是十分友好。 补充 GitHub上的代码都是开源的，请勿做伸手党，自己查看我的GitHub链接（见底端），或者看material主题的demo blog的博主的GitHub。 上述链接是我搭建完之后查找的，可以作为参考。 我搭建博客的时间花费了一天，之后花了三天的时间换了四到五个主题，最后选择了material。如果您不喜欢这个主题可以自行到hexo的网站查找其他主题。"},{"title":"gallery","date":"2018-02-25T17:58:47.409Z","updated":"2018-02-23T11:41:04.503Z","comments":true,"path":"gallery.html","permalink":"http://AndyQianq.github.io/gallery.html","excerpt":"","text":""},{"title":"links","date":"2018-02-23T11:41:34.764Z","updated":"2018-02-23T11:41:34.764Z","comments":true,"path":"links.html","permalink":"http://AndyQianq.github.io/links.html","excerpt":"","text":""},{"title":"tags","date":"2018-02-23T11:38:09.566Z","updated":"2018-02-23T11:38:09.566Z","comments":true,"path":"tags.html","permalink":"http://AndyQianq.github.io/tags.html","excerpt":"","text":""},{"title":"Work","date":"2018-03-13T16:54:56.468Z","updated":"2018-03-13T16:54:56.468Z","comments":true,"path":"work.html","permalink":"http://AndyQianq.github.io/work.html","excerpt":"","text":"写在前面：function secondToDate(second){if(!second){return 0}var time=new Array(0,0,0,0,0);if(second>=365*24*3600){time[0]=parseInt(second/(365*24*3600));second%=365*24*3600}if(second>=24*3600){time[1]=parseInt(second/(24*3600));second%=24*3600}if(second>=3600){time[2]=parseInt(second/3600);second%=3600}if(second>=60){time[3]=parseInt(second/60);second%=60}if(second>0){time[4]=second}return time};function setTime(){var create_time=Math.round(new Date(Date.UTC(2017,12,03,20,14,19)).getTime()/1000);var timestamp=Math.round((new Date().getTime()+8*60*60*1000)/1000);currentTime=secondToDate((timestamp-create_time));currentTimeHtml=currentTime[0]+'年'+currentTime[1]+'天'+currentTime[2]+'时'+currentTime[3]+'分'+currentTime[4]+'秒';document.getElementById(\"htmer_time\").innerHTML=currentTimeHtml}setInterval(setTime,1000); 接新时间： 二次元发表的作品总集，不定时更新。 安发表的次序排放，特别喜欢的会考虑置顶。 这里放置的作品为提供猫耳fm链接和bilibili链接的作品。如果与我合作的策划也希望将作品放置此处，希望您在猫耳fm和bilibili发表，并提供链接。 后期作品就是一个百合剧，爱听不听╭(╯^╰)╮staff表 策划-子易成霜【天惹噜工作室】@三朝元老 导演-林苏酥【天惹噜工作室】 @苏爆天下的双木 编剧-青玄【712配音组】 @青玄家的兔子君 板绘-叶里木 @叶里木 美工-孤尘【天惹噜工作室】@孤尘_X 剧后-檀樱【月聆风裳】 @檀no樱 视频-白云生谷【天惹噜工作室】 @乐乐_Luo 代码宣-花埘【心之所向】 @花埘家 cast表 青团-覆卿辞【笙莘剧社】 @覆卿辞才不是小屁股 虾球-澹台七娘【十四桥】 @可以吃的澹台七娘 报幕-千冬【天惹噜工作室】 @千冬参上 策划-乌漆麻薯【天惹噜工作室】 @乌漆麻薯 编剧-千肆璎珞【马猴烧酒工作室】 @千肆璎珞 汉子-大汤圆【無名】@大汤圆牧桑 音频 视频链接 第一集 第二集 第三集 第四集 第五集 第六集 第七集 第八集（to be continue） 时光启示录Staff：策划：棠导演：乘舟美工：k剧后：檀樱【月聆风裳】 Cast：百年：墨云温和：冷皇【声声漫】奶奶：千尘落尽【凌霄剧团】小孩1：紫轩【雲天广播剧社】小孩2：萌生姐：阿虐学生1：啊时时【听音悦】学生2：流氓【江湖小白工作室】 链接 元夕STAFF 策划：白云生谷【天惹噜工作室】@乐乐_Luo 导演：小薯【天惹噜工作室】@乌漆麻薯 监制：子易成霜【天惹噜工作室】@三朝元老 编剧：小乖 美工：昙萦 后期：檀樱【月聆风裳】@檀no樱 代码宣：花埘【心之所向】@花埘家 CAST 零：木小柏【裔美声社】@CV木小柏 夕：沫生【椒盐火腿】@沫生Impression 淳：Void 【KA.U】@Void-空 路人甲：千冬【天惹噜工作室】@千冬参上 路人乙：郑灵枫【七弦上】@郑灵枫YA 路人丙：狐狸少爷【马猴烧酒工作室】@CV狐狸少爷 县老爷：东皇太一【未来之声】@CV东皇太一 法师: 东皇太一【未来之声】@CV东皇太一 下人、干活的：千冬【天惹噜工作室】@千冬参上 报幕：丘【狐说工作室】@丘朝曲暮 ED《过路》 策划：白云生谷【天惹噜工作室】@乐乐_Luo 原曲：其实都没有-杨宗纬 填词：玖言【天惹噜工作室】@莫常Y 翻唱：梨落【老蟋蟀工作室】@落or三岁 后期：狐狸少爷【天惹噜工作室】@CV狐狸少爷 美工：昙萦 音频 君臣【鱼歌剧团】出品 全一期原创古风耽美广播剧 STAFF： 策划：释然【鱼歌剧团】 编剧、导演：暗翼 后期：檀樱【月聆风裳】 美工：醉晚 山不在【鱼歌剧团】 Cast： 苏青：油饼【鱼歌剧团】 历遥：杳一【一语成诺工作室】 历遥心腹：酱油了 瓶【鱼歌剧团】 宫女：梦见【鱼歌剧团】 侍卫：南夏【鱼歌剧团】 Ed：《恨晚》 原曲：《烟花易冷》 填词：岩暨【鱼歌剧团】 翻唱：吾未识君时 音频b站链接点击此处 感谢您观看到最后"},{"title":"Resume","date":"2018-02-23T05:52:40.646Z","updated":"2018-02-19T05:07:41.622Z","comments":true,"path":"resume.html","permalink":"http://AndyQianq.github.io/resume.html","excerpt":"","text":"Information Name：a065be9fe61b02421 Birthday：0051616d96a4de047 Gender：female Connect Tel：c2ecb3948d07733edc701a758ca9a9c101 WeChat：ce627823a38db384780524b97aa9758207 QQ：69997fc0b02a328fef70f03825b87f6a98 Education University：HFUT Major：Information Security"},{"title":"Satoh Takeru","date":"2018-02-19T06:35:46.000Z","updated":"2018-03-13T18:10:11.226Z","comments":true,"path":"takeru.html","permalink":"http://AndyQianq.github.io/takeru.html","excerpt":"","text":"其实一开始对takeru的颜并不是很感冒，第一眼看上去并不是我的菜，更何况第一次知道他还是因为《浪客剑心》，而看浪客剑心的缘由是因为从初中追到高中的小说《龙族》里面有提到过这个漫画，仅仅一句。于是先看了剧场版的，结果，我的天！剧场版的《浪客剑心》简直直戳我的心啊！！！虽然里面的星霜篇作者和月伸宏并不是很赞同这一版的结局，可是我还是很喜欢。觉得在1999年日本就可以做出《浪客剑心（追忆篇）》这样的作品，简直了！ 然后马不停蹄的去追了真人版电影，哈哈哈现在想起了还是15年高三的时候，用着家里的那一台用了4年的联想笔记本，在没有耳机的情况下，午夜偷偷的看完了。 其实一开始看电影的时候我对于扮演剑心的Takeru并没有很深的印象，有时候还会觉得，emmm，这个男主角也太可爱了一点吧，不怎么像我心目中的剑心。后来才知道，不去追95集的动画这样说是不太负责的，因为古桥一浩执导那一版动画里面的剑心和剧场版里面的是不太一样哒。 然后就开始追这部电影的花絮和日综，结果，结果，结果。。。。我对这个颜居然越看越顺眼了？？？到后面觉得，这个男孩子有着一张和少女一样的颜，但是绝绝对对的草食系猫男啊啊啊啊，而且动作敏捷。什么？电影里面的打戏没有用替身？喜欢玩游戏，而且绝对不在游戏上不认输，事实上游戏玩的也很好，哈哈哈哈。 怎么办，就是这个男人，颠覆了我积累了17年的审美观（捂脸），主要改变总结为以下几点 1）男生只有一米七好像也可以很帅？？？？ 2）男生长得可爱一点好像也没什么大问题？？？ 于是在周围同学还在追着韩国欧巴的时候，我居然一下子跳到了日圈。。。 于是高考结束之后，疯狂的把Takeru的所有电影，日综全部看完了。然而真正让我沦陷了是一部玛丽苏电影，（pia，我错了我错了）名字叫做《她爱上了我的谎言》（简称她谎，又翻译成《迷雾中的蝴蝶》）。 哇塞，这一部电影简直就是激起了我陈了17年的少女心。准确的说，这部电影的定位不是很少女向，虽然女主是女高中生，穿着jk制服谈恋爱的那种。。。但是男主真的是很有魅力的设定啊，尤其是抱着吉他在编曲的时候，简直浑身上下散发着想让人谈恋爱的荷尔蒙。 然后才发现，这个男人居然这么好看，简直360度的无死角啊！！！ 于是死守了好几年的柏原崇一下子就被我放弃了，转身就投入了takeru的怀抱～～～ 之后又看了从12年就开始播的TAKETERE个人节目。不得不说日本的娱乐周边行业很用心啊。每期的时长都有一个多小时，而且没有广告，单纯的就是takeru和粉丝的互动，有点想唠家常，哈哈哈。 于是就看着他从原先羞涩的少年模样变成了现在的猫大爷哈哈哈哈哈。 有人统计说，takeru是日本演艺界发型尝试最多的男艺人，期间尝试过各种各样的诡异发型，例如非洲人数的脏脏辫，各种杀马特挑染，如果不是真爱，我都不相信我会去看很久很久以前的一部叫做《假面超人》的特摄片，只是为了去观看我糖的颜艺，哈哈哈哈。 16年的时候还尝试了寸头，结果出乎意料的好看，很清爽的样子，果然还是脸过硬啊。 20才出头的他，当时一副清瘦的少年样子，牙齿也还没有长好，站在一堆帅哥里面，总有一种羞涩的感觉。 21岁的时候，在《摇滚新乐园》里面也是出演高中生，好像总是比自己的年纪要年轻很多。断断续续的弹着吉他，唱歌还有一点点跑调，虽然声音很好听。结果因为拍好电影，get到了新技能——弹得一手好吉他。 23岁的时候，去演舞台剧《罗密欧与朱丽叶》，简直还是花一般的少年模样，和同台的十元比起来还要少女。但是为了一场脱衣服的场景，去练了一身的肌肉。 2012年到2014年，拍摄《浪客剑心》系列电影的时候，真正的红了，还认识了one OK rock的主唱Taka，成为了好基友。 之后接的戏路宽了很多，不在演高中生，定位更加的成熟。少了一分当年少年时候的单纯，多了一分年华给予的沉淀。"}],"posts":[{"title":"江南雨","slug":"江南雨","date":"2018-05-20T16:48:28.000Z","updated":"2018-05-20T16:54:03.793Z","comments":true,"path":"2018/05/21/江南雨/","link":"","permalink":"http://AndyQianq.github.io/2018/05/21/江南雨/","excerpt":"","text":"文案： 清和月初七，闻雨声阵阵，回忆起儿时家乡的那个街巷。若是江南少了烟雨，怕十分韵味里也少了三分灵气了吧。 A： 雨纷纷院内枇杷接水盛天濛濛阶前麻雀过玉门一阵阵巷头小哥卖花声三五人亭内闲语话清晨 B： 滴答滴答一声声春闺里有几人梦几人窗外咿呀惊了魂披衣起身望归程 C： 一笔一笔寄归人樱桃熟了不知有几成再过几月莲子出犹恐未归落了尘","categories":[{"name":"poetry","slug":"poetry","permalink":"http://AndyQianq.github.io/categories/poetry/"}],"tags":[{"name":"歌词","slug":"歌词","permalink":"http://AndyQianq.github.io/tags/歌词/"}]},{"title":"YOLO算法","slug":"YOLO","date":"2018-03-29T14:10:28.000Z","updated":"2018-03-29T18:15:37.805Z","comments":true,"path":"2018/03/29/YOLO/","link":"","permalink":"http://AndyQianq.github.io/2018/03/29/YOLO/","excerpt":"","text":"写在前面 因为本学期选择了图像处理这门课程，课程设计中有答辩环节，需要描述一个算法的介绍。 这里整理资料准备下周的答辩。 之后的情况会更新到下周二答辩，也就是4月3日。 仅供参考日后参考使用，同时也是记录学习情况。 算法背景算法内容 核心思想 从R-CNN到Fast R-CNN一直采用的思路是proposal+分类（proposal提供位置信息，分类提供类别信息）精度已经很高，但是速度还不行。YOLO提供了另一种更为直接的思路：直接在输出层回归bounding box的位置和bounding box所属的类别（整张图作为网络的输入，把Object Detection的问题转化成一个REgression问题）。 主要特点 速度快，能够达到实时的要求。在Titan X的GPU上能够达到45帧每秒。 使用全图作为Context信息，背景错误比较少。 泛化能力强。 大致流程 1）Resize成448✖️448，图片分割成7✖️7网格（cell） 2）CNN提取特征和预测：卷积部分负责提特征。全链接部分负责预测： a)7✖️7✖️2=98个bounding box（bbox）的坐标和是否有物体的confidence。b)7✖️7=49个cell所属20个物体的概率。 3）过滤bbox（通过nms） 具体请查看 算法实现 YOLO的安装 安装预备库 1）安装git工具2）安装bunzip23）安装gcc 下载安装包 123git clone https://github.com/pjreddie/darknetcd darknetmake 下载预训练的超参数，也是权重 1wget https://pjreddie.com/media/files/yolo.weights 执行预测 1./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg 参考资料参考论文:YOLO9000:Better&amp;Faster&amp;Stronger(En)参考论文：YOLO9000:Better&amp;Faster&amp;Stronger(cn)darknet提供的开源测试","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"image processing","slug":"image-processing","permalink":"http://AndyQianq.github.io/tags/image-processing/"}]},{"title":"YOLO9000:Better&Faster&Stronger","slug":"YOLO9000","date":"2018-03-27T14:10:28.000Z","updated":"2018-03-29T18:17:22.620Z","comments":true,"path":"2018/03/27/YOLO9000/","link":"","permalink":"http://AndyQianq.github.io/2018/03/27/YOLO9000/","excerpt":"","text":"写在前面 这是一篇英文论文的翻译，原文出处：YOLO9000:Better&amp;Faster&amp;Stronger 仅供学习参考使用，在此分享。 简介 我们推出了YOLO9000，这是一款先进的实时物体检测系统，可检测9000多种物体类别。 首先，我们提出对YOLO检测方法的各种改进，既有新颖性，也有以前的工作。 改进后的模型YOLOv2在PASCAL VOC和COCO等标准检测任务中处于技术领先地位。 使用一种新颖的多尺度训练方法，同一YOLOv2模型可以以不同的尺寸运行，从而在速度和精度之间提供了一个简单的折衷。 在67 FPS时，YOLOv2在VOC 2007上获得了76.8 mAP。在40 FPS时，YOLOv2获得78.6 mAP，比ResNet和SSD等Faster R-CNN等先进方法更出色，同时运行速度更快。 最后，我们提出了一种联合训练对象检测和分类的方法。使用这种方法，我们在COCO检测数据集和ImageNet分类数据集上同时训练YOLO9000。 我们的联合培训使YOLO9000能够预测未标注检测数据的对象类别的检测结果。 我们在ImageNet检测任务上验证了我们的方法。 YOLO9000在ImageNet检测验证集上获得19.7 mAP，尽管只有200个类别中的44个具有检测数据。 在没有COCO的156班上，YOLO9000获得16.0 mAP。 但YOLO可以检测超过200个班级; 它预测超过9000个不同的对象类别的检测。 它仍然是实时运行的。 介绍 通用物体检测应该快速，准确，并且能够识别各种各样的物体。 自引入神经网络以来，检测框架变得越来越快速和准确。 但是，大多数检测方法仍然局限于一小部分对象。 与分类和标记等其他任务的数据集相比，当前的对象检测数据集有限。 最常见的检测数据集包含成千上万到数十万个具有几十到几百个标签的图像[3] [10] [2]。 分类数据集拥有数以百万计的图像，数十万或数十万个类别[20] [2]。我们希望将检测扩展到对象分类的级别。 但是，标记图像进行检测要比标记分类或标记要便宜得多（标记通常是用户免费提供的）。因此，我们不可能在近期内看到与分类数据集具有相同比例的检测数据集。 我们提出了一种新方法来利用我们已有的大量分类数据，并用它来扩大当前检测系统的范围。 我们的方法使用对象分类的分层视图，使我们可以将不同的数据集组合在一起。 我们还提出了一种联合训练算法，使我们能够在检测和分类数据上训练物体检测器。 我们的方法利用标记检测图像来学习精确定位对象，同时使用分类图像来增加词汇量和健壮性。 使用这种方法，我们训练YOLO9000，这是一个实时的物体检测器，可以检测超过9000种不同的物体类型。 首先，我们改进YOLO基础检测系统，生产出最先进的实时检测器YOLOv2。 然后，我们使用我们的数据集组合方法和联合训练算法来训练来自ImageNet的9000多个类的模型以及COCO的检测数据。 我们所有的代码和预先训练好的模型都可以在http://pjreddie.com/yolo9000/在线获得。 更优 YOLO相对于最先进的检测系统存在各种缺点。 YOLO与Fast R-CNN相比的误差分析表明，YOLO产生了大量的定位误差。此外，与区域提案方法相比，YOLO召回率相对较低。因此，我们主要关注改善召回和本地化，同时保持分类准确性。 计算机视觉通常趋向于更大，更深的网络[6] [18] [17]。更好的性能通常取决于培训更大的网络或将多个模型集合在一起。但是，对于YOLOv2，我们需要一个更精确的检测器，它仍然很快。我们不是扩大我们的网络，而是简化网络，然后让表示更易于学习。我们将过去工作中的各种想法与我们自己的新颖概念汇集在一起​​，以提高YOLO的性能。表2列出了结果总结。 批量标准化批量归一化可以显着改善收敛性，同时不需要其他形式的正则化[7]。通过在YOLO中的所有卷积图层上添加批量标准化，我们在mAP中获得了2％以上的改进。批量标准化也有助于模型的正规化。通过批量标准化，我们可以消除模型中的压差而不会过度拟合。 高分辨率分类器所有最先进的检测方法都使用在ImageNet上预先训练好的分类器[16]。从AlexNet开始，大多数分类器在小于256×256的输入图像上操作[8]。最初的YOLO以224×224的速度训练分类器网络，并将分辨率提高到448以进行检测。这意味着网络必须 同时切换到学习对象检测并适应新的输入分辨率。 对于YOLOv2，我们首先在分辨率网络上以448×448的全分辨率对ImageNet上的10个时期进行微调。这给网络时间调整其滤波器以更好地处理更高分辨率的输入。然后，我们对检测结果网络进行微调。这个高分辨率的分类网络使我们的mAP增加了近4％。 与锚箱相卷积YOLO直接使用卷积特征提取器顶部的完全连接图层来预测边界框的坐标。直接预测坐标更快R-CNN使用手工选取的先验预测边界框[15]。仅使用卷积层，Faster R-CNN中的区域提议网络（RPN）可预测锚箱的偏移和置信度。由于预测层是卷积的，所以RPN在特征映射中的每个位置处预测这些偏移。预测偏移而不是坐标可以简化问题并使网络更易于学习。 我们从YOLO中移除完全连接的层，并使用锚箱来预测边界框。首先我们消除一个池层，以使网络卷积层的输出具有更高的分辨率。我们还缩小网络，使其在416个输入图像上运行，而不是448×448。我们这样做是因为我们需要在我们的特征映射中有奇数个位置，因此只有一个中心单元。对象，尤其是大对象，往往占据图像的中心，所以最好在中心拥有一个位置来预测这些对象，而不是四个位置都在附近。 YOLO的卷积层将图像缩小32倍，所以通过使用416的输入图像，我们得到13×13的输出特征图。 当我们移动到锚箱时，我们也将类预测机制与空间位置分离开来，而是预测每个锚箱的类和对象。在YOLO之后，对象性预测仍然预测了基本事实和提议框的IOU，并且类别预测预测了该类别的条件概率，因为存在对象。 使用锚箱，我们会得到精确度的小幅下降。 YOLO仅预测每个图像98个盒子，但使用锚盒我们的模型预测超过一千个。如果没有锚箱，我们的中间模型将获得69.5 mAP，回收率为81％。使用锚箱，我们的模型获得了69.2 mAP，回收率为88％。尽管mAP减少，召回率的增加意味着我们的模型有更大的改进空间。 维度集群与YOLO一起使用时，我们会遇到两个问题。 首先是盒子尺寸是手工挑选的。 网络可以学习适当调整方框，但是如果我们选择更好的网络先验，我们可以让网络更容易学习预测好的检测结果。 我们不用手工选择先验，而是在训练集边界框上运行k均值聚类，自动找到良好的先验。 如果我们使用具有欧几里得距离的标准k-means，那么较大的盒子比较小的盒子产生更多的误差。 然而，我们真正想要的是先进的，导致良好的IOU分数，这是独立于框的大小。 因此对于我们的距离度量我们使用： d(box, centroid) = 1 − IOU(box, centroid) 我们对各种k值运行k均值，并画出最接近质心的均值IOU，见图2.我们选择k = 5作为模型复杂度和高回忆率之间的良好折衷。 集群质心与手工选取的锚定盒显着不同。 有更少的短，宽盒子和更高，更薄的盒子。 我们将平均IOU与我们的聚类策略中的最接近之前的比较以及表1中的手工选取的锚定框进行比较。仅有5个先验质心的性能类似于9个锚定框，平均IOU为61.0，而60.9。 如果我们使用9个质心，我们会看到更高的平均IOU。 这表明使用k-means生成我们的边界框可以更好地表示模型并使其更容易学习。 图2：VOC和COCO上的聚类框尺寸。 我们在边界框的维上运行k-means聚类，以获得我们模型的良好先验。 左图显示了我们通过k的各种选择获得的平均IOU。 我们发现k = 5为召回与模型的复杂性提供了良好的折衷。 右图显示了VOC和COCO的相对质心。 这两种产品都喜欢更薄，更高的盒子，而COCO的尺寸比VOC更大。 VOC 2007上物体的平均IOU与其最接近的，未经修改的物体之前使用不同的生成方法。 聚类结果比使用手工选取的先验结果要好得多。 直接位置预测当在YOLO中使用锚箱时，我们会遇到第二个问题：模型不稳定，尤其是在早期迭代过程中。 大多数不稳定来自于预测盒子的（x，y）位置。 在区域提议网络中，网络预测值t_x和t_y以及（x，y）中心坐标计算如下： x=(t_x ∗w_a)−x_ay = (t_y ∗ h_a) − y_a 例如，对t_x = 1的预测会使该框向右移动锚盒的宽度，预测t_x = -1会将其向左移动相同的量。 这个公式是不受约束的，所以任何锚点盒都可以在图像中的任何一点结束，而不管这个盒子在哪个位置预测。随机初始化模型需要很长时间才能稳定以预测合理的偏移。 我们没有预测偏移，而是遵循YOLO的方法并预测相对于网格单元位置的位置坐标。这使得事实的界限在0到1之间。我们使用逻辑激活来限制网络的预测落在这个范围内。 网络预测输出特征映射中每个单元的5个边界框。网络预测每个边界框的5个坐标，t_x，t_y，t_w，t_h和t_o。如果单元格从图像的左上角偏移了（c_x，c_y）并且之前的边界框具有宽度和高度p_w，p_h，则预测对应于： b_x =σ(t_x)+c_x b_y =σ(t_y)+c_yb_w =p_we^t_w b_h = p_he^t_h Pr(object) ∗ IOU(b,object) = σ(t_o) 由于我们限制位置预测，因此参数化更容易学习，从而使网络更加稳定。 使用维度集群并直接预测边界框中心位置，可以使YOLO比锚定框的版本提高近5％。 细粒度特征这是修改后的YOLO预测13×13特征地图上的检测结果。 虽然这对于大型物体是足够的，但它可以从用于定位较小物体的更细粒度特征中受益。 更快的R-CNN和SSD都在网络中的各种功能地图上运行提案网络，以获得一系列的解决方案。 我们采取不同的方法，只需添加一个直通层，以26×26的分辨率从较早的层中提取特征。 图3：具有维度先验和位置预测的边界框。 我们预测盒子的宽度和高度作为集群质心的偏移量。 我们使用sigmoid函数预测相对于滤波器应用位置的盒子的中心坐标。 直通层将高分辨率特征与低分辨率特征连接起来，将相邻特征堆叠到不同的通道中，而不是空间位置，类似于ResNet中的身份映射。 这将26×26×512特征地图变成13×13×2048特征地图，其可以与原始特征级联。 我们的探测器运行在这张扩展功能地图的顶部，以便它可以访问细粒度的功能。 这使性能提高了1％。 图4：VOC 2007的准确性和速度。 多尺度训练原来的YOLO使用448×448的输入分辨率。通过添加锚箱，我们将分辨率更改为416×416。但是，由于我们的模型仅使用卷积层和汇聚层，因此可以实时调整大小。我们希望YOLOv2能够在不同尺寸的图像上运行，因此我们可以将其训练到模型中。 我们不需要修改输入图像大小，而是每隔几次迭代就改变一次网络。每10个批次我们的网络会随机选择一个新的图像尺寸大小。由于我们的模型缩减了32倍，所以我们从32的倍数中抽取：{320,352，…，608}。因此，最小的选项是320×320，最大的是608×608。我们调整网络的尺寸并继续训练。 这个权值迫使网络学习如何在各种输入维度上做好预测。这意味着相同的网络可以预测不同分辨率下的检测结果。网络在较小的尺寸下运行速度更快，因此YOLOv2在速度和准确性之间提供了一个简单的折衷。 在低分辨率下，YOLOv2作为一种便宜，相当准确的检测器工作。 在288×288的速度下，它的运行速度超过90 FPS，而MAP几乎与Fast R-CNN一样好。 这使其成为小型GPU，高帧率视频或多视频流的理想选择。 在高分辨率下YOLOv2是一款先进的探测器，其挥发性有机化合物VOC（VOC）为78.6 mAP，同时仍以高于实时速度运行。请参阅表3，了解YOLOv2与VOC 2007其他框架的比较。 表3：检测PA S C A L的框架VOC 2007。YOLOv2比先前的检测方法更快，更准确。 它也可以以不同的分辨率运行，以便在速度和准确性之间轻松折衷。 每个YOLOv2条目实际上都是具有相同权重的相同训练模型，只是以不同的大小进行评估。 所有的时间信息都在Geforce GTX Titan X（原始的，而不是Pascal模型）上。 进一步的实验。 我们对YOLOv2进行VOC 2012检测培训。表4显示了YOLOv2与其他最先进的检测系统的比较性能。 YOLOv2运行速度远高于竞争方法，达到73.4 mAP。 我们还训练COCO，并与表5中的其他方法进行比较。在VOC度量（IOU = 0.5）上，YOLOv2获得44.0 mAP，与SSD和R-CNN相当。 YOLOv2比先前的检测方法更快，更准确。 它也可以以不同的分辨率运行，以便在速度和准确性之间轻松折衷。 每个YOLOv2条目实际上都是具有相同权重的相同训练模型，只是以不同的大小进行评估。 所有的时间信息都在Geforce GTX Titan X（原始的，而不是Pascal模型）上。 更快 我们希望检测结果准确，但我们也希望检测速度更快。 大多数用于检测的应用程序（如机器人技术或自动驾驶汽车）都依赖于低延迟预测。 为了最大限度地提高性能，我们设计YOLOv2从头开始。 表2：从YOLO到YOLOv2的路径。 大多数列出的设计决策都会导致MAP显着增加。 有两个例外情况是切换到带有锚点盒的全卷积网络并使用新网络。 切换到锚盒风格的方法增加召回率，而不改变mAP，同时使用33％的新网络削减计算。表4：PASCAL VOC2012测试检测结果。 YOLOv2的性能与采用ResNet和SSD512的更快的R-CNN等最先进的探测器相媲美，速度提高2至10倍。 大多数检测框架依赖于VGG-16作为基本特征提取器[17]。 VGG-16是一个功能强大，准确的分类网络，但它不必要的复杂。 VGG-16的卷积层需要306.90亿浮点运算，以224×224分辨率在单个图像上进行一次单通。 YOLO框架使用基于Googlenet架构的自定义网络[19]。 这个网络比VGG-16更快，只有85.2亿次运行才能进行正向传球。 然而，它的准确性略低于VGG-16。对于224×224的单作，精度为前5的YOLO定制型号获得88.0％的ImageNet，而VGG-16则为90.0％。 表5：COCO test-dev2015的结果。 表格改编自[11]表6:darknet-19 Darknet-19。我们提出了一个新的分类模型作为YOLOv2的基础。我们的模型建立在网络设计的先前工作以及该领域的常识上。与VGG模型类似，我们大多使用3×3滤波器，并且在逐步汇集步骤后使用两倍的通道数[17]。在Network in Network（NIN）的工作之后，我们使用全局平均汇集来做预测，并使用1×1滤波器来压缩3×3卷积之间的特征表示[9]。我们使用批量归一化来稳定训练，加速收敛，并规范模型[7]。 我们的最后一个模型叫做Darknet-19，它有19个卷积层和5个Maxpool层。 Darknet-19只需要55.8亿次操作来处理图像，但在ImageNet上实现了72.9％的前1精度和91.2％的前5精度。 分类训练。我们使用DarkNet神经网络框架，使用随机梯度下降，初始学习率为0.1，多项式速率衰减为4，权重衰减为0.0005，动量为0.9，在标准ImageNet 1000类别分类数据集上对网络进行160个历元的训练[13]。在训练过程中，我们使用标准数据增强技巧，包括随机作物，旋转和色相，饱和度和曝光转移。 如上所述，在我们对224×224图像进行初始训练之后，我们对网络进行了细调，448。为了进行这种微调，我们使用上述参数进行训练，但仅用10个时期，并且以10- 3。在这个更高的分辨率下，我们的网络实现了76.5％的前1精度和93.3％的前5精度。 培训检测。我们通过去除最后一个卷积层来修改这个网络，并在每个1024个滤波器后面加上3个3×3卷积层，然后在最后的1×1卷积层上添加我们需要检测的输出数量。对于挥发性有机化合物，我们预测5个盒子，每盒5个坐标，每盒20个等级，所以有125个过滤器我们还添加了从最后的3×3×512层到倒数第二层卷积层的直通层，以便我们的模型可以使用细粒度特征。 我们训练网络160个时代，初始学习率为10-3，在60和90时代除以10。 我们使用0.0005的重量衰减和0.9的动量。我们对随机作物，色彩转换等YOLO和SSD使用类似的数据增强。我们对COCO和VOC使用相同的培训策略。 更强 我们提出了一个联合培训分类和检测数据的机制。 我们的方法使用了用于检测的图像来学习检测特定信息，如边界框坐标预测和对象以及如何对常见对象进行分类。 它使用仅具有类标签的图像来扩展其可检测类别的数量。 在训练期间，我们混合来自检测和分类数据集的图像。 当我们的网络看到标记为检测的图像时，我们可以根据完整的YOLOv2损失函数进行反向传播。 当它看到分类图像时，我们只会反向传播体系结构中分类特定部分的损失。 这种方法带来了一些挑战。检测数据集只有通用对象和通用标签，如“狗”或“船”。分类数据集具有更广泛和更深的标签范围。 ImageNet拥有多种犬种，包括“诺福克梗”，“约克夏犬”和“Bedlington梗”。如果我们想在两个数据集上进行训练，则需要采用一致的方式来合并这些标签。 大多数分类方法使用跨所有可能类别的softmax层来计算最终概率分布。使用softmax假定类是相互排斥的。这给组合数据集带来了问题，例如，您不希望将ImageNet和COCO结合使用，因为类“诺福克梗”和“狗”并不相互排斥。 相反，我们可以使用多标签模型来组合不会互相排斥的数据集。这个方法忽略了我们所知道的关于数据的所有结构，例如所有的COCO类都是相互独立的。 分层分类ImageNet标签是从WordNet中提取的，这是一个结构概念及其相互关系的语言数据库[12]。在WordNet中，“诺福克梗”和“约克夏梗”都是“猎犬”的下位词，它是一种“猎狗”，它是一种“狗”，它是一种“犬”，等等。分类为标签假设一个扁平结构，但是对于组合数据集，结构正是我们所需要的。 WordNet的结构是有向图，而不是树，因为语言很复杂。例如，“狗”既是一种“犬”又是一种“家养动物”，它们都是WordNet中的同义词。我们不使用完整的图结构，而是通过从ImageNet中的概念构建分层树来简化问题。 为了构建这棵树，我们检查ImaNet中的视觉名词并查看它们通过WordNet图到根节点的路径，在这种情况下是“物理对象”。许多synsets只有一条路径通过图形，所以首先我们将所有这些路径添加到我们的树中。然后，我们反复检查我们留下的概念，并尽可能少地添加生成树的路径。所以如果一个概念有两条通向根的路径，一条路径会为我们的树添加三条边，另一条路只会增加一条边，我们选择较短的路径。 最终的结果是WordTree，一个视觉概念的层次模型。为了使用WordTree进行分类，我们预测每个节点的条件概率，以给出synset的每个同义词的下位概率。例如，在“梗”节点我们预测： P r(Norfolk terrier|terrier) P r(Yorkshire terrier|terrier) P r(Bedlington terrier|terrier)… 如果我们想要计算某个特定节点的绝对概率，我们只需沿着通过树到达根节点的路径并乘以条件概率。所以如果我们想知道一幅图片是否属于诺福克梗，我们计算： P r(Norfolk terrier) = P r(Norfolk terrier|terrier) ∗P r(terrier|hunting dog)∗…∗∗P r(mammal|P r(animal)∗P r(animal|physical object) 出于分类目的，我们假设图像包含一个对象：P r（物理对象）= 1。 为了验证这种方法，我们在使用1000类ImageNet构建的WordTree上训练Darknet-19模型。为了构建WordTree1k，我们在所有中间节点中添加了将标签空间从1000扩展到1369的中间节点。在训练过程中，我们在树上传播地面真实标签，这样如果图像被标记为“诺福克梗”，它也会被标记作为“狗”和“哺乳动物”等。为了计算条件概率，我们的模型预测了1369个值的向量，并且我们计算了所有系统集上的softmax，它们是相同概念的下位词，见图5。 图5：对ImageNet与WordTree的预测。 大多数ImaNet模型使用一个大的softmax来预测概率分布。 使用WordTree，我们通过共同的下位词执行多个softmax操作。 使用与以前相同的训练参数，我们的分层Darknet-19达到了71.9％的前1精度和90.4％的前5精度。尽管增加了369个附加概念，并且我们的网络预测了树状结构，但我们的精度仅略微下降。以这种方式进行分类也有一些好处。性能会降低新的或未知的对象类别。例如，如果网络看到一张狗的照片，但不确定它是什么类型的狗，它仍然会高度自信地预测“狗”，但在下位数中散布的可信度较低。 该配方也适用于检测。现在，我们不用假定每个图像都有一个对象，而是使用YOLOv2的对象预测器给我们P r（物理对象）的值。检测器预测边界框和概率树。我们遍历树，在每次拆分中获取最高的置信度路径，直到达到某个阈值，并且我们预测该对象类。 数据集与WordTree的组合我们可以使用WordTree以可行的方式将多个数据集组合在一起。我们只需将数据集中的类别映射到树中的synsets即可。图6显示了一个使用WordTree组合来自ImageNet和COCO的标签的示例。 WordNet非常多样化，所以我们可以将这种技术用于大多数数据集。 联合分类和检测现在我们可以使用WordTree组合数据集，我们可以在分类和检测上训练联合模型。我们想要训练一个非常大规模的探测器，所以我们使用COCO探测数据集和完整ImageNet版本中的前9000个类创建我们的组合数据集。我们还需要评估我们的方法，以便从ImageNet检测挑战中添加任何尚未包含的类。该数据集的相应WordTree具有9418个类。 ImageNet是一个更大的数据集，所以我们通过对COCO进行过采样来平衡数据集，使得ImageNet仅增大4：1。 使用这个数据集我们训练YOLO9000。我们使用基础的YOLOv2架构，但只有3个先验而不是5个来限制输出大小。当我们的网络看到一个检测图像时，我们会像平常一样反向传播丢失。对于分类损失，我们只会在标签的相应级别或更高的级别上反向传播损失。例如，如果标签是“狗”，我们确实将任何错误分配给树中的预测，“德国牧羊犬”与“黄金猎犬”，因为我们没有这些信息。 图6：使用WordTree层次结构组合数据集。 使用WordNet概念图，我们构建了视觉概念的分层树。 然后，我们可以通过将数据集中的类映射到树中的synsets来合并数据集。 出于说明目的，这是WordTree的简化视图。 当它看到分类图像时，我们只是反向分类丢失。要做到这一点，我们只需找到预测该类别最高概率的边界框，然后在预测的树上计算损失。我们还假设预测框与至少0.3 IOU的基础真实标签重叠，并且基于这个假设我们反向传播对象损失。 利用这种联合训练，YOLO9000学习使用COCO中的检测数据来查找图像中的对象，并学习使用来自ImageNet的数据对各种这些对象进行分类。 我们在ImageNet检测任务上评估YOLO9000。 ImageNet的检测任务与COCO共享44个对象类别，这意味着YOLO9000只能看到大多数测试图像的分类数据，而不是检测数据。 YOLO9000在不相交的156个对象类中总共获得19.7 mAP，其中16.0 mAP，它从未见过任何标记的检测数据。这个mAP高于DPM的结果，但YOLO9000仅在部分监督下接受不同数据集的训练[4]。它也同时实时检测9000个其他对象类别。 当我们分析YOLO9000在ImaNet上的表现时，我们发现它可以很好地学习动物的新物种，但是会随着服装和设备等学习类别而不断变化。 表7：ImageNet上的YOLO9000最佳和最差类别。156个弱监督班的AP和AP最高和最低的班级。 YOLO9000为各种各样的动物学习好模型，但与诸如服装或设备等新课程斗争。 新动物比较容易学习，因为在COCO中动物的物体预测总体上很好。相反，COCO对于任何类型的服装都没有包装盒标签，只适用于个人，所以YOLO9000很难模仿“太阳镜”或“游泳裤”等类别。 总结 我们介绍YOLOv2和YOLO9000，即时检测系统。 YOLOv2在各种检测数据集中都是最先进的，并且比其他检测系统更快。此外，它可以在各种图像尺寸下运行，以提供速度和准确性之间的平滑折衷。 YOLO9000是一个通过联合优化检测和分类来检测超过9000个对象类别的实时框架。我们使用WordTree将各种来源的数据和我们的联合优化技术相结合，在ImageNet和COCO上同时进行培训。 YOLO9000向关闭检测和分类之间的数据集大小差距迈出了坚实的一步。 我们的许多技术都是在对象检测之外进行推广。 ImageNet的WordTree表示为图像分类提供了更丰富，更详细的输出空间。使用分层分类的数据集组合在分类和分割领域将会很有用。像多尺度训练这样的训练技术可以为各种视觉任务提供益处。 对于未来的工作，我们希望使用类似的技术进行弱监督图像分割。我们还计划使用更强大的匹配策略来改善我们的检测结果，以在训练期间将弱标签分配给分类数据。计算机视觉拥有大量的标记数据。我们将继续寻找方法，将不同的数据来源和数据结构结合在一起，形成更强大的视觉世界模型。 参考 [1] S. Bell, C. L. Zitnick, K. Bala, and R. Girshick. Inside- outside net: Detecting objects in context with skip pooling and recurrent neural networks. arXiv preprint arXiv:1512.04143, 2015. 6[2] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei- Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on, pages 248–255. IEEE, 2009. 1[3] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) chal- lenge. International journal of computer vision, 88(2):303– 338, 2010. 1[4] P. F. Felzenszwalb, R. B. Girshick, and D. McAllester. Discriminatively trained deformable part models, release 4. http://people.cs.uchicago.edu/ pff/latent-release4/. 8[5] R. B. Girshick. Fast R-CNN. CoRR, abs/1504.08083, 2015. 4, 5, 6[6] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learn- ing for image recognition. arXiv preprint arXiv:1512.03385, 2015. 2, 4, 5[7] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015. 2, 5[8] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012. 2[9] M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.4400, 2013. 5[10] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ra- manan, P. Dolla ́r, and C. L. Zitnick. Microsoft coco: Com- mon objects in context. In European Conference on Com- puter Vision, pages 740–755. Springer, 2014. 1, 6[11] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, and S. E. Reed. SSD: single shot multibox detector. CoRR, abs/1512.02325, 2015. 4, 5, 6[12] G. A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. J. Miller. Introduction to wordnet: An on-line lexical database. International journal of lexicography, 3(4):235–244, 1990. 6[13] J. Redmon. Darknet: Open source neural networks in c. http://pjreddie.com/darknet/, 2013–2016. 5[14] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection. arXiv preprint arXiv:1506.02640, 2015. 4, 5[15] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: To- wards real-time object detection with region proposal net- works. arXiv preprint arXiv:1506.01497, 2015. 2, 3, 4, 5, 6[16] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. 2[17] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. 2, 5[18] C. Szegedy, S. Ioffe, and V. Vanhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR, abs/1602.07261, 2016. 2[19] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. CoRR, abs/1409.4842, 2014. 5[20] B.Thomee,D.A.Shamma,G.Friedland,B.Elizalde,K.Ni, D. Poland, D. Borth, and L.-J. Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):64–73, 2016. 19","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"image processing","slug":"image-processing","permalink":"http://AndyQianq.github.io/tags/image-processing/"}]},{"title":"Weka的使用","slug":"weka的使用","date":"2018-03-27T14:10:28.000Z","updated":"2018-03-29T18:15:16.500Z","comments":true,"path":"2018/03/27/weka的使用/","link":"","permalink":"http://AndyQianq.github.io/2018/03/27/weka的使用/","excerpt":"","text":"写在前面 这是一个数据挖掘的课程小作业，主要是介绍weka是如何使用以及怎么使用一些开源的数据挖掘算法。 使用的系统是macOS，分析的数据为：bank-data。 Weka的全名是怀卡托智能分析环境（Waikato Environment for Knowledge Analysis），是一款免费的，非商业化（与之对应的是SPSS公司商业数据挖掘产品–Clementine ）的，基于JAVA环境下开源的机器学习（machine learning）以及数据挖掘（data mining）软件。它和它的源代码可在其官方网站下载。有趣的是，该软件的缩写WEKA也是新西兰独有的一种鸟名，而Weka的主要开发者同时恰好来自新西兰的the University of Waikato。 数据格式： 识别ARFF文件的重要依据是分行，因此不能在这种文件里随意的断行。空行（或全是空格的行）将被忽略。 以“%”开始的行为注释，weka将忽略这些行。 除去注释之后，整个ARFF文件将可以分成两个部分 决策树： 测试结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788=== Run information ===Scheme: weka.classifiers.trees.REPTree -M 2 -V 0.001 -N 3 -S 1 -L -1 -I 0.0Relation: bank-data-weka.filters.unsupervised.attribute.Remove-R1Instances: 600Attributes: 11 age sex region income married children car save_act current_act mortgage pepTest mode: 10-fold cross-validation=== Classifier model (full training set) ===REPTree============income &lt; 29669.75| children &lt; 1.5| | children &lt; 0.5| | | married = NO| | | | mortgage = NO : YES (23/3) [9/0]| | | | mortgage = YES| | | | | save_act = NO : YES (6/0) [3/0]| | | | | save_act = YES : NO (11/0) [2/0]| | | married = YES| | | | age &lt; 58.5| | | | | income &lt; 23455.35| | | | | | mortgage = NO : NO (36/4) [17/5]| | | | | | mortgage = YES| | | | | | | region = INNER_CITY : YES (6/3) [6/1]| | | | | | | region = TOWN : NO (6/0) [1/0]| | | | | | | region = RURAL : YES (2/1) [2/1]| | | | | | | region = SUBURBAN : YES (2/0) [3/1]| | | | | income &gt;= 23455.35 : NO (21/0) [10/3]| | | | age &gt;= 58.5 : YES (4/0) [4/2]| | children &gt;= 0.5| | | income &lt; 15155.85 : NO (16/1) [6/2]| | | income &gt;= 15155.85 : YES (40/4) [22/0]| children &gt;= 1.5 : NO (77/9) [44/3]income &gt;= 29669.75| children &lt; 0.5| | married = NO| | | mortgage = NO : YES (10/0) [6/0]| | | mortgage = YES : NO (7/1) [6/2]| | married = YES : NO (41/6) [19/1]| children &gt;= 0.5| | children &lt; 2.5 : YES (73/2) [29/5]| | children &gt;= 2.5| | | income &lt; 44387.55 : NO (12/2) [10/0]| | | income &gt;= 44387.55 : YES (7/0) [1/0]Size of the tree : 35Time taken to build model: 0.02 seconds=== Stratified cross-validation ====== Summary ===Correctly Classified Instances 521 86.8333 %Incorrectly Classified Instances 79 13.1667 %Kappa statistic 0.734 Mean absolute error 0.2 Root mean squared error 0.3277Relative absolute error 40.2928 %Root relative squared error 65.7915 %Total Number of Instances 600 === Detailed Accuracy By Class === TP Rate FP Rate Precision Recall F-Measure MCC ROC Area PRC Area Class 0.839 0.107 0.868 0.839 0.853 0.734 0.900 0.883 YES 0.893 0.161 0.869 0.893 0.880 0.734 0.900 0.895 NOWeighted Avg. 0.868 0.136 0.868 0.868 0.868 0.734 0.900 0.890 === Confusion Matrix === a b &lt;-- classified as 230 44 | a = YES 35 291 | b = NO 决策树 每个分支结点对应一个对象集合和一个属性选择，每个分支对应一个测试条件。 叶子结点对应一个类别判断 采用的是自上而下、递归、分而治之的方法。 CLS的算法分析 优点：简捷、直观 缺点：1）抗干扰能力弱，噪音数据难免，算法对噪音敏感；2）容易受到无关属性的印象，导致规则的繁琐；3）受属性选择次序也会影响结果；4）只能发现部分规则。 ID3算法分析 与CLS的区别在于选择了最高的信息增益。 什么是信息熵？","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"Data mining","slug":"Data-mining","permalink":"http://AndyQianq.github.io/tags/Data-mining/"}]},{"title":"网站攻击的可能情况","slug":"网站攻击可能的情况","date":"2018-03-26T14:10:28.000Z","updated":"2018-03-26T14:16:42.815Z","comments":true,"path":"2018/03/26/网站攻击可能的情况/","link":"","permalink":"http://AndyQianq.github.io/2018/03/26/网站攻击可能的情况/","excerpt":"","text":"跨站点脚本攻击 是当前web应用中最危险和最普遍的漏洞之一。 通常用于发动cookie窃取、恶意软件传播（蠕虫攻击），会话劫持，恶意重定向。 攻击者将恶意的javascript代码注入到网站页面中，这样“受害者”的浏览器就会执行攻击者编写的恶意脚本。 这种漏洞容易找到，但是很难修补。 由于在网页设计中，我们把级联样式表叫做CSS。因此为了避免混淆，我们把cross-site scripting称为XSS。 如果对用户输入的数据没有进行正确的编码和过滤，这个被注入恶意脚本将被发送给其他用户。对浏览器来说，它没有办法知道它不应该相信一个脚本的合法性。浏览器会正常地把这个脚本当成普通脚本执行，这个时候恶意的操作就不可避免的发生了。大部分的时候，XSS是用来窃取cookie，或窃取有效用户的会话令牌session，以此来进行会话劫持。 从本质上理解，XSS就是一种HTML的注入，和传统的buffer overflow是类似 cookie的作用 Cookie，有时也用其复数形式Cookies，指某些网站为了辨别用户身份、进行session跟踪而储存在用户本地终端上的数据(通常经过加密)。定义于RFC2109(已废弃)，最新取代的规范是RFC2965。 也就是说，cookie是用户和服务器之间的桥梁。服务器可以使用session来保存用户的身份信息(ID,购物车等)，但是需要用户在访问网页(发送HTTP数据包)的时候附带上相应的cookie，通过cookie中的特定值来识别sessionID，才能把单独用户和单独的session联系起来。cookie是有状态HTTP交互的一种重要机制。 XSS攻击的种类 对XSS的分类没有明确的标准，但是业界普遍将XSS攻击分为三类。反射型XSS，存储XSS，DOM Based XSS 非持久性跨站点脚本攻击 非持久性XSS也称为反射型跨网站漏洞，是最常见的类型的XSS。漏洞产生的原因是攻击者注入的数据反映在响应中。一个典型的非持久性XSS包含一个带XSS攻击向量的链接。 持久的跨站点脚本攻击 持久型跨站点脚本也被称为存储跨站点脚本。它一般发生在XSS攻击向量（一般指XSS攻击代码）存储在网站数据库，当一个页面被用户打开的时候执行。每当用户打开浏览器、脚本执行。持久的XSS相比非持久型的XSS攻击的危害性更大，因为每当用户打开了页面，查看内容时脚本将自动执行。谷歌的orkut曾经就遭受到XSS。 基于dom的跨站点脚本攻击 基于DOM的XSS有时候也称为type0 XSS。当用户能够通过交互修改浏览器页面中的DOM并显示在浏览器上时，就有可能产生这种漏洞，从效果上来说它也是反射型XSS。 XSS漏洞产生的原因 跨站点脚本的原因是程序员对用户的信任，开发人员轻松地认为用户永远不会试图执行什么出格的是钱，所以他们创建应用程序的时候没有使用任何额外的代码来过滤用户输入以阻止任何恶意的活动。另一个原因是，这种攻击有许多的变体，用制造出一种行之有效的XSS过滤器是一件比较困难的事情。 缓冲区溢出攻击 其目的在于扰乱具有某些特权运行的程序的功能，这样可以使得攻击者取得吃程序的控制权，如果该程序具有足够的权限，那么整个主机就被控制了。一般而言，攻击者攻击ROOT程序，然后执行类似“exec（sh）”的执行代码来获得root权限的shell。为了达到这个目的，攻击者必须达到如下的两个目标： 1.在程序的地址空间里安排适当的代码2.通过适当的初始化寄存器和内存，让程序跳转到入侵者安排的地址空间执行。 根据这个两个目标对缓存区溢出的哦你关机进行分类。 在程序的地址空间里安排适当的代码的方法 两种在被攻击程序地址空间里安排攻击代码的方法： 1.植入法 攻击者向被攻击的程序输入的一个字符串，程序会把这个字符串放到缓存区里。这个字符串包含的资料是可以在这个被攻击的硬件【平台上运行的指令序列。在这里，攻击者用被攻击程序的缓存区来存放攻击代码。缓存区可以设在任何地方。 2.利用已经存在的代码 有时候，攻击者想要的代码已经在被攻击的程序中来，攻击者所要做的只是对代码传递一些参数。比如，攻击代码要求执行“exec(bin/sh)”，而在libc库中的代码执行“exec（arg）”，其中arg是一个指向一个字符串的指针参数，那么攻击者只要把传入的参数指针改向指向“/bin/sh”。 DOS攻击SYN洪水攻击 要理解doe攻击，首先要理解TCP连接的三次握手过程。 在TCP/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接。 第一次握手：建立连接时，客户端发送SYN包（（SYN=i）到服务器，并进入SYN SEND状态，等待服务器确认）第二次握手：服务器收到SYN包必须确认客户的SYN (ACK=i+1 )，同时自己也发送一个SYN包((SYN=j)}即SYN+ACK包，此时服务器进入SYN-RECV状态; 第三次握手:客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ACK=j+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手，客户端与服务器开始传送数据。 半连接: 收到SYN包而还未收到ACK包时的连接状态称为半连接，即尚未完全完成三次握手的TCP连接。 半连接队列: 在三次握手协议中，服务器维护一个半连接队列，该队列为每个客户端的SYN包(SYN=i )开设一个条目，该条目表明服务器已收到SYN包，并向客户发出确认，正在等待客户的确认包。这些条目所标识的连接在服务器处于SYN-RECV状态，当服务器收到客户的确认包时，删除该条目，服务器进入ESTABLISHED状态。 Backlog参数: 表示半连接队列的最大容纳数目。 SYN-ACK重传次数: 服务器发送完SYN-ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传，如果重传次数超过系统规定的最大重传次数，系统将该连接信息、从半连接队列中删除。注意，每次重传等待的时间不一定相同。 半连接存活时间:是指半连接队列的条目存活的最长时间，也即服务从收到SYN包到确认这个报文无效的最长时间，该时间值是所有重传请求包的最长等待时间总和。有时也称半连接存活时间为Timeout时间、SYN-RECV存活时间。 上面三个参数对系统的TCP连接状况有很大影响。 SYN洪水攻击属于DoS攻击的一种，它利用TCP协议缺陷，通过发送大量的半连接请求，耗费CPU和内存资源。SYN攻击除了能影响主机外，还可以危害路由器、防火墙等网络系统，事实上SYN攻击并不管目标是什么系统，只要这些系统打开TCP服务就可以实施。从图4-3可看到，服务器接收到连接请求(SYN=i )将此信息加入未连接队列，并发送请求包给客户端( SYN=j,ACK=i+1 )，此时进入SYN-RECV状态。当服务器未收到客户端的确认包时，重发请求包，一直到超时，才将此条目从未连接队列删除。配合IP欺骗，SYN攻击能达到很好的效果，通常，客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送SYN包，服务器回复确认包，并等待客户的确认，由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN 请求被丢弃，目标系统运行缓慢，严重者引起网络堵塞甚至系统瘫痪。 防御方法 第一种是缩短SYN Timeout时间 第二种方法是设置SYN Cookie，就是给每一个请求连接的IP地址分配一个Cookie，如果短时间内连续受到某个IP的重复SYN报文，就认定是受到了攻击，以后从这个IP地址来的包会被一概丢弃。&gt;netstat -n -p tcp &gt;result.txt SYN Cookies 的使用不与任何协议定义冲突，照理来说它该和所有的 TCP 实现兼容。然而，当 SYN Cookies 使用的时候，会发生两种值得注意的变化： 首先，服务器只能编码八种 MSS 数值，因为只有 3 位二进制空间可用。 其次，这个服务器必须拒绝所有的TCP 选用项，例如大型窗口和时间戳，因为服务器会在信息被用其他方式存储时丢弃 SYN 队列条目。 尽管这些限制将不可避免地导致一个不如最佳的体验，它们的效果很少被客户端注意到——这些改变只在被攻击时值得注意。在这样的情况下，牺牲 TCP 选项来保护连接一般被认为是合乎情理的。 Linux内核从 2.6.26 版本开始为 TCP 选用项加入了有限的支持，通过把它们编码在时间戳内实现。 较新的TCP Cookie 传输（TCPCT）标准被设计用来克服 SYN Cookies 的这些问题，并且在各种方面改进这套机制。不像 SYN Cookies，TCPCT 是一个 TCP 拓展并且要求两端点都支持 TCPCT。 死亡之ping (pingofdeath) ICMP(InternetControlMessageProtocol，Internet控制信息协议)在Internet上用于错误处理和传递控制信息。最普通的ping程序就是这个功能。而在TCP/IP的RFC文档中对包的最大尺寸都有严格限制规定，许多操作系统的TCP/IP协议栈都规定ICMP包大小为64KB，且在对包的标题头进行读取之后，要根据该标题头里包含的信息来为有效载荷生成缓冲区。”PingofDeath”就是故意产生畸形的测试Ping（PacketInternetGroper）包，声称自己的尺寸超过ICMP上限，也就是加载的尺寸超过64KB上限，使未采取保护措施的网络系统出现内存分配错误，导致TCP/IP协议栈崩溃，最终接收方宕机。 防御方法 1、用高级设置法预防Ping 2、用网络防火墙阻隔Ping使用防火墙来阻隔Ping是最简单有效的方法，现在基本上所有的防火墙在默认情况下都启用了ICMP过滤的功能。 3、启用IP安全策略防Ping 4、修改TTL值防Ping许多入侵者喜欢用TTL值来判断操作系统，他们首先会Ping一下你的机子，如看到TTL值为128就认为你的系统为Windows NT/2000，如果TTL值为32则认为目标主机操作系统为Windows 95/98，如果为TTL值为255/64就认为是UNIX/Linux操作系统。既然入侵者相信TTL值所反应出来的结果，那么我们不妨修改TTL值来欺骗入侵者，达到保护系统的目的 5、防火墙在处理Ping of Death攻击报文时，是通过判定数据包的大小是否大于65535字节，如果数据包大于65535字节，则判定为攻击报文，直接丢弃。 UDP泛洪 UDPflood攻击：如今在Internet上UDP（用户数据包协议）的应用比较广泛，很多提供WWW和Mail等服务设备通常是使用Unix的服务器，它们默认打开一些被黑客恶意利用的UDP服务。如echo服务会显示接收到的每一个数据包，而原本作为测试功能的chargen服务会在收到每一个数据包时随机反馈一些字符。UDPflood假冒攻击就是利用这两个简单的TCP/IP服务的漏洞进行恶意攻击，通过伪造与某一主机的Chargen服务之间的一次的UDP连接，回复地址指向开着Echo服务的一台主机，通过将Chargen和Echo服务互指，来回传送毫无用处且占满带宽的垃圾数据，在两台主机之间生成足够多的无用数据流，这一拒绝服务攻击飞快地导致网络可用带宽耗尽。 防御方法 UDP协议与TCP 协议不同，是无连接状态的协议，并且UDP应用协议五花八门，差异极大，因此针对UDP Flood的防护非常困难。其防护要根据具体情况对待： 判断包大小，如果是大包攻击则使用防止UDP碎片方法：根据攻击包大小设定包碎片重组大小，通常不小于1500.在极端情况下，可以考虑丢弃所有UDP碎片。 攻击端口为业务端口：根据该业务UDP最大包长设置UDP最大包大小以过滤异常流量。 攻击端口为非业务端口：一个是丢弃所有UDP包，可能会误伤正常业务;一个是建立UDP连接规则，要求所有去往该端口的UDP包，必须首先与TCP端口建立TCP连接。不过这种方法需要很专业的防火墙或其他防护设备支持。 Land（LandAttack）攻击 在Land攻击中，黑客利用一个特别打造的SYN包–它的原地址和目标地址都被设置成某一个服务器地址进行攻击。此举将导致接受服务器向它自己的地址发送SYN-ACK消息， 结果这个地址又发回ACK消息并创建一个空连接，每一个这样的连接都将保留直到超时，在Land攻击下，许多UNIX将崩溃，NT变得极其缓慢（大约持续五分钟）。 防御方法 防火墙在处理Land攻击报文时，通过检查TCP报文的源地址和目的地址是否相同，或者TCP报文的源地址是否为环回地址，如果是则丢弃。 泪滴攻击 对于一些大的IP数据包，往往需要对其进行拆分传送，这是为了迎合链路层的MTU（最大传输单元）的要求。比如，一个6 000字节的IP包，在MTU为2 000的链路上传输的时候，就需要分成3个IP 包。在IP报头中有一个偏移字段和一个拆分标志（MF）。如果MF标志设置为1，则表示这个IP包是一个大IP包的片段，其中偏移字段指出了这个片段在整个IP包中的位置。例如，对一个6 000字 节的IP包进行拆分（MTU为2 000），则3个片段中偏移字段的值依次为0，2 000，4 000。这样接收端在全部接收完IP数据包后，就可以根据这些信息重新组装这几个分次接收的拆分IP包。在这 里就有一个安全漏洞可以利用了，就是如果黑客们在截取IP数据包后，把偏移字段设置成不正确的值，这样接收端在收到这些分拆的数据包后，就不能按数据包中的偏移字段值正确组合这些拆分的数据包，但接收端会不断尝试，这样就可能致使目标计算机操作系统因资源耗尽而崩溃。 防御方法 检测这类攻击的方法是对接收到的分片数据包进行分析，计算数据包的片偏移量（Offset）是否有误。反攻击的方法是添加系统补丁程序，丢弃收到的病态分片数据包并对这种攻击进行审计。尽可能采用最新的操作系统，或者在防火墙上设置分段重组功能，由防火墙先接收到同一原包中的所有拆分数据包，然后完成重组工作，而不是直接转发。因为防火墙上可以设置当出现重叠字段时所采用的规则。 IP地址扫描攻击 IP地址扫描攻击是攻击者运用ICMP报文（如Ping和Tracert命令）探测目标地址，或者使用TCP/UDP报文对一定地址发起连接，通过判断是否有应答报文，以确定哪些目标系统确实存活着并且连接在目标网络上。 防御方法 防火墙对收到的TCP、UDP、ICMP报文进行检测，当某源IP地址连续发送报文的目的IP地址与前一个报文的目的IP地址不同时，则记为一次异常，当异常次数超过预定义的阈值时，则认为该源IP的行为为IP地址扫描行为，防火墙会将该源IP地址加入黑名单。 Smurf攻击 Smurf攻击通过使用将回复地址设置成受害网络的广播地址的ICMP应答请求(ping)数据包，来淹没受害主机，最终导致该网络的所有主机都对此ICMP应答请求做出答复，导致网络阻塞。更加复杂的Smurf将源地址改为第三方的受害者，最终导致第三方崩溃。 攻击的过程是这样的：Woodlly Attacker向一个具有大量主机和因特网连接的网络的广播地址发送一个欺骗性Ping分组（echo 请求），这个目标网络被称为反弹站点，而欺骗性Ping分组的源地址就是Woolly希望攻击的系统。 这种攻击的前提是，路由器接收到这个发送给IP广播地址（如206.121.73.255）的分组后，会认为这就是广播分组，并且把以太网广播地址FF:FF:FF:FF:FF:FF:映射过来。这样路由器因因特网上接收到该分组，会对本地网段中的所有主机进行广播。 读者肯定能够想到下面会发生什么情况。网段中的所有主机都会向欺骗性分组的IP地址发送echo响应信息。如果这是一个很大的以太网段，可以会有500个以上的主机对收到的echo请求进行回复。 由于多数系统都会尽快地处理ICMP传输信息，Woodlly Attacker把分组的源地址设置为目标系统，因此目标系统都很快就会被大量的echo信息吞没，这样轻而易举地就能够阻止该系统处理其它任何网络传输，从而引起拒绝为正常系统服务。 这种攻击不仅影响目标系统，还影响目标公司的因特网连接。如果反弹站点具有T3连接（45Mbps），而目标系统所在的公司使用的是租用线路（56Kbps），则所有进出该公司的通讯都会停止下来。 这种攻击现在已经很少见,大多数的网络已经对这种攻击免疫了. 防御方法 配置路由器禁止IP广播包进网 配置网络上所有计算机的操作系统，禁止对目标地址为广播地址的ICMP包响应。 被攻击目标与ISP协商，有ISP暂时阻止这些流量。 对于从本网络向外部网络发送的数据包，本网络应该将其源地址为其他网络的这部分数据包过。 Fraggle攻击 类似于Smurf，使用UDP应答消息而非ICMP。UDP端口7（ECHO）和端口19（Chargen）在收到UDP报文后，都会产生回应。在UDP的7号端口收到报文后，会回应收到的内容，而UDP的19号端口在收到报文后，会产生一串字符流。它们都同ICMP一样，会产生大量无用的应答报文，占满网路带宽。攻击者可以向子网广播地址发送源地址为受害网络或受害主机的UDP包，端口号用7或19.子网络启用了此功能的每个系统都会向受害者的主机做出响应，从而引发大量的包，导致受害网络的阻塞或受害主机的崩溃；子网上没有启动这些功能的系统将产生一个ICMP不可达的消息，因而仍然消耗带宽。也可将源端口改为Chargen。目的端口为ECHO，这样会自动不停地产生回应报文，其危害性更大。 防御方法 检查进入防火墙的UDP报文，若目的端口号为7或19，则直接拒绝，并将攻击记录到日志，否则允许通过。 电子邮件炸弹 电子邮件炸弹是最古老的匿名攻击之一，通过设置一台机器不断的大量的向同一地址发送电子邮件，攻击者能够耗尽接受者网络的带宽。 防御方法 对邮件地址进行配置，自动删除来自同一主机的过量或重复的消息。 畸形消息攻击 各类操作系统上的许多服务都存在此类问题，由于这些服务在处理信息之前没有进行适当正确的错误校验，在收到畸形的信息可能会崩溃。 防御方法 打最新的服务补丁。","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"web","slug":"web","permalink":"http://AndyQianq.github.io/tags/web/"}]},{"title":"SQL Injection","slug":"SQL Injection","date":"2018-03-24T14:10:28.000Z","updated":"2018-03-26T14:17:54.520Z","comments":true,"path":"2018/03/24/SQL Injection/","link":"","permalink":"http://AndyQianq.github.io/2018/03/24/SQL Injection/","excerpt":"","text":"SQL注入 在编写代码过程中，没有对用户输入的数据的合法性进行判断，使用应用程序存在安全隐患。 攻击者可以提交一些精心构造的数据库查询代码，根据返回的结果，获得某些他想知道的数据，就是所谓的SQL注入（SQL injection）。 受影响的系统：对输入的参数不进行检查和过滤的系统。 简单的SQL注入的实例： 假设这么一个情景： 一个网页的后台入口处需要验证用户名和密码，验证程序的SQL语句这样写： Select * from admin where user=’TxtBox1.txt’and pass=’TxtBox2.txt’ 如果有户填写的用户名和密码都是：’abc’or’1’=1 那么将导致SQL语句：Select * from admin where user=’abc’or’1’=1and pass=’abc’or’1’=1这条语句是永真式，那么攻击者就成功登录了后台，这就是最简单的SQL注入方式。 SQL注入过程 （1）寻找可能存在的SQL注入漏洞的链接 （2）测试该网站是否有SQL注入漏洞 （3）猜管理员账号表 （4）猜测管理员表中的字段 （5）猜测用户名和密码长度 防范的方法： （1）过滤可能的SQL注入语句的组合 比如过滤逗号，单引号，分号等；如果select、delete、from、union之类的字符串同时出现多个的话，也要引起重视；最好对用户提交的参数的长度也进行判断。 （2）摒弃摒弃动态的SQL语句 摒弃动态SQL语句，改用用户存储过程来访问和操作数据。这需要在建立数据库后，仔细考虑web程序需要对数据库操作。这样，用户提交的数据将不是用来生成动态SQL语句，而是确确实实地作为参数传递给存储过程，从而有效阻断了SQL注入的途径。","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"Java web","slug":"Java-web","permalink":"http://AndyQianq.github.io/tags/Java-web/"},{"name":"SQL","slug":"SQL","permalink":"http://AndyQianq.github.io/tags/SQL/"}]},{"title":"A Neural Conversational Model","slug":"A Neural Conversational Model","date":"2018-03-22T04:16:46.000Z","updated":"2018-03-26T10:43:36.165Z","comments":true,"path":"2018/03/22/A Neural Conversational Model/","link":"","permalink":"http://AndyQianq.github.io/2018/03/22/A Neural Conversational Model/","excerpt":"","text":"写在前面 这是一篇论文的翻译，论文的原名：A Neural Conversational Model 论文的原链接：A Neural Conversational Model 仅供学习使用，特翻译成中文，方便广大读者和笔者自己学习。 神经交流模型简介 会话建模是自然语言理解和机器智能的一个重要的任务。尽管之前已经有人提出了一些方法，但是他们都是针对一个有人为规定的具体领域（例如，飞机票的预定）。在这篇文章里，我们将展现一个简单的基于最近被提出的句子来搭建一个框架。我们的模型将会根据上一个句子或者是整个对话的句子来进行对话。我们模型的优点在于他是从端到端的训练，因此就少了对于人为规定的依赖。我们发现经过一个大语库训练之后，这个简单的模型可以生成一些对话。我们初步的结果显示，尽管优化了一些错误的优化函数，这个模型可以对话的很好。它不仅可以在具体的领域数据集中获取知识，而且可以在大型的、杂乱的、一般的数据集（例如电影字幕）也同样可以。在特定领域的IT帮助台数据集上，该模型可以通过对话找到技术问题的解决方案。在一个有噪声的开源领域电影副本数据集，这个模型可以执行简单形式的常识推理。正如预期，我们也发现了缺乏一致性也是我们模型的常见失效模式。 介绍 在端到端的神经网络训练进步引领了很多领域的显著进步，例如语言识别，计算机视觉，和语言处理。最近的工作显示，神经网络可以做的不仅仅是分类，它同时还可以用来从一些复杂的结构映射到另一个复杂的结构映射。例如在这个任务中，它可以从一个序列映射到另一个在自然语言理解中有直接应用的序列。这个框架的主要优点是它只需要很少的特征工程和领域特异性，同时匹配或者超越最先进的结果。在我们看来，这种进步可以让研究人员能够处理通过领域知识可能无法获得的任务，或者对于那些难以手动设计规则的任务。会话建模可以直接受益于这种配置，因为它需要查询和响应之间的映射。由于这种映射的复杂性，转换建模以前被设计为非常狭窄的领域，主要是在特征工程方面。 在这项工作中，我们试验了对话建模任务，将它转换为预测下一个序列的任务，给出了使用循环网络的先前序列或序列。我们发现这种方法在生成流畅而准确的对话答复方面可以做得出人意料。我们在来自IT帮助台对话数据集的聊天会话中测试模型，并发现该模型有时可以跟踪问题并为用户提供有用的答案。我们还试验了从嘈杂的电影字幕数据集中获得的对话，并发现该模型可以进行自然对话，有时还可以执行简单形式的常识推理。 在这两种情况下，与n-gram模型相比，经常性网络获得更好的困惑并捕获重要的远程相关。 最近的工作 在端到端的神经网络训练进步引领了很多领域的显著进步，例如语言识别，计算机视觉，和语言处理。最近的工作显示，神经网络可以做的不仅仅是分类，它同时还可以用来从一些复杂的结构映射到另一个复杂的结构映射。例如在这个任务中，它可以从一个序列映射到另一个在自然语言理解中有直接应用的序列。这个框架的主要优点是它只需要很少的特征工程和领域特异性，同时匹配或者超越最先进的结果。在我们看来，这种进步可以让研究人员能够处理通过领域知识可能无法获得的任务，或者对于那些难以手动设计规则的任务。会话建模可以直接受益于这种配置，因为它需要查询和响应之间的映射。由于这种映射的复杂性，转换建模以前被设计为非常狭窄的领域，主要是在特征工程方面。 在这项工作中，我们试验了对话建模任务，将它转换为预测下一个序列的任务，给出了使用循环网络的先前序列或序列。我们发现这种方法在生成流畅而准确的对话答复方面可以做得出人意料。我们在来自IT帮助台对话数据集的聊天会话中测试模型，并发现该模型有时可以跟踪问题并为用户提供有用的答案。我们还试验了从嘈杂的电影字幕数据集中获得的对话，并发现该模型可以进行自然对话，有时还可以执行简单形式的常识推理。 在这两种情况下，与n-gram模型相比，经常性网络获得更好的困惑并捕获重要的远程相关。 模型 我们的方法利用了序列到序列（seq2seq）框架。该模型基于循环神经网络，该网络每次读取一个令牌的输入序列，并预测输出序列，每次也是一个令牌。 在训练期间，真实的输出序列被赋予模型，所以学习可以通过反向传播完成。根据上下文，该模型被训练以最大化正确序列的交叉熵。在推断过程中，假设没有观察到真实的输出序列，我们只需输入预测的输出标记作为输入来预测下一个输出。 这是一种“贪心”的推理方法。一个不那么贪婪的方法是使用波束搜索，并在前面的步骤提供几个候选人到下一步。 预测序列可以根据序列的概率进行选择。 注释：反向传播算法（Back-propagation）是一种与最优化方法（如梯度下降法）结合使用的，用来训练神经网络的常见算法。该方法计算对网络中所有权重计算损失函数的梯度。这个梯度会反馈给最优化方法，用来更新权值以最小化损失函数。反向传播要求有对每个输入值想得到的已知输入，来计算损失函数梯度。因此，它通常被认为是一种监督式学习方法，虽然它也用在一些无监督网络中。它是多层前馈网络的Delta规则的推广，可以用链式法则对每层迭代计算梯度。反向传播要求人工神经元（或“节点”）对激励函数可微。 具体而言，假设我们观察两轮谈话：第一个人发出“ABC”，第二个人回复“WXYZ”。我们可以使用循环神经网络，并训练将“ABC”映射到“WXYZ”，如上图1所示。模型在接收序列符号“【eos】”结束时的隐藏状态可以被视为思维向量，因为它存储了句子或思想“ABC”的信息。这个模型的优势在于它的简单性和通用性。 我们可以将此模型用于机器翻译，问答/回答和对话，而不会在架构上发生重大变化。 将这种技术应用到对话建模中也很简单：输入序列可以是迄今为止已转换的内容（上下文）和输出序列的回复。但是，与简单的翻译任务不同，像序列到序列的模型由于几个明显的简化而无法成功地“解决”对话建模问题：目标函数被优化并不能实现实际达到的目标 通过人类通信，这通常是较长期的并且基于信息交换而不是下一步预测。 缺乏确保一致性和一般世界知识的模型是纯粹无监督模型的另一个明显限制。 数据集 在我们的实验中，我们使用了两个数据集：一个封闭域IT帮助台故障诊断数据集和一个开放域电影抄本数据集。 两个数据集的详细信息如下。 封闭域IT帮助台故障诊断数据集 在我们的第一组实验中，我们使用了从IT帮助台故障排除聊天服务中提取的数据集。 在这项服务中，消费者面临与计算机相关的问题，而专家则通过交谈和解决方案来帮助他们。典型的交互（或线程）长度为400个字，轮流显示。 我们的训练集包含30M令牌，3M令牌用作验证。 执行了一些清理工作，例如删除常用名称，数字和完整URL。 开放域电影抄本数据集 我们还在开放域电影抄本上测试了我们的模型（Tiedemann，2009）。 该数据集由XML格式的电影对话组成。它包含由电影中的角色发出的句子。 我们应用了一个简单的处理步骤，从数据集中移除XML标签和明显的非对话文本（例如超链接）。由于轮到并没有明确指出，我们假设连续的句子是由不同的角色说出的。 我们训练了我们的模型以预测下一句话，并且我们为每个句子做了这个（注意这使得我们的数据集大小加倍，因为每个句子既用于上下文又用作目标）。我们的训练和验证分割包含62M句子（923M令牌）作为训练样例，验证集有26M个句子（395M令牌）。 分割是以这样一种方式完成的，即一对句子中的每个句子或者一起出现在训练集或测试集中，但不能同时出现在两个句子中。 与以前的数据集不同，OpenSubtitles非常大，而且相当嘈杂，因为连续的句子可能由同一个字符发出。鉴于电影的广泛范围，这是一个开放域对话数据集，与技术故障排除数据集形成对比。 实验 在本节中，我们用两个数据集描述实验结果，并显示与我们训练的系统的交互作用的一些样本。 我们还将我们的系统与基于流行规则的机器人（CleverBot1）的性能进行了比较，这些机器人使用人类评估对200个问题进行评估。 封闭域IT帮助台故障诊断实验 在这个实验中，我们使用随机梯度下降梯度下降法来训练单层LSTM和1024个存储器单元。 词汇由最常见的20K字组成，其中包括特殊标记，表示转身和演员。 在收敛时，这个模型实现了8个困惑，而n-gram模型达到了18个。下面是几个最常见的IT问题（远程访问，软件崩溃和密码问题）的几个模拟故障排除会话）。 在这些对话中，机器是我们的神经对话模型，人类是与之互动的人类演员。 对话1：VPN问题。 描述你的问题：我在访问vpn时遇到问题 Machine: hiHuman: helloMachine: could you please let me know what are the operating systems you are using ?Human: i am using linuxMachine: ok it was in the ssl vpn on which you stated it was brokenMachine: please check if you are logged in to corp networkMachine: what is the error that you are running pleaseHuman: i am seeing an error related to vpnMachine: what is the error message that you are getting when connecting to vpn using network connect ?Human: connection refused or something like thatMachine: may i know the version of network connect you connect ?Human: i am not sure i know thatMachine: is the network connect prompting for any user certificateMachine: ?Human: yesMachine: are you at home or at work at the mo- ment ?Machine: office ?Human: i am at homeMachine: try thisMachine: goto page and enter your name and passwordHuman: doneMachine: try logging in with and check if its working fine nowHuman: yes , now it works !Machine: greatMachine: anything else that i can helpHuman: no , that was very usefulMachine: you are other than : )Machine: have a nice night（确实包含有关vpn访问的信息。） 对话2： 浏览器问题。 Machine: hiHuman: hiMachine: could you please let me know what is the operating system you are using ?Human: linuxMachine: ok this is the issue with the system per- formance , nasser , tools .Human: what is that ?Machine: is it a windows machine ?Machine: we have linux on your machine .Machine: is it windows xp or windows 7 ?Human: i am using linuxMachine: let me take a remote of your machine and check if issue has been pushed properly .Human: okMachine: please open terminal and run the be- low commands in one computer :Machine: sudo apt - get updateMachine: sudo apt - get upgradeMachine: sudo - updaterHuman: doneMachine: let me try connecting nowHuman: okMachine: its doneMachine: should use the second or hit run on the backgroundHuman: doneMachine: try signing out now and follow the prompts as per the message given aboveMachine: shd i reboot the machine .Human: ok , please go aheadMachine: once its completed please try to loginHuman: sureMachine: please ping me back once you have tried to loginMachine: are we still connectedHuman: i now logged inMachine: thanks for your confirmation Human: what should i do now ?Machine: wait for 1 5 minutes to complete the login policyMachine: and then try logging inHuman: okMachine: is there anything else to help you ?Human: let my try browsing a little bit and if it keeps crashing i will let you knowMachine: sure will doMachine: seems the mail is not loadingMachine: are we still connected to the chat ?Machine: Human: it seems good now , cool , thank you , byeMachine: you , tooMachine: bye 开放域电影抄本实验 在这个实验中，我们使用梯度剪裁的AdaGrad训练了一个双层LSTM。 LSTM的每一层都有4096个存储单元，我们建立了一个包含最常见的100K字的词汇表。 为了加快soft-max，我们在将信息馈送给分类器之前将存储单元投影到2048个线性单元。 在收敛时，验证集合上的递归模型的困惑是17.我们平滑的5克模型达到了28的困惑度。有趣的是，增加Bahdanau等人的软注意机制并没有显着 改善训练或验证集的困惑。 模型样本： 除了困惑性测量外，我们的简单复现模型经常会产生合理的答案。 以下是几个示例 - 答案对，它们允许我们在从电影中获取OpenSubtitles的嘈杂而庞大的数据集时，了解模型的功能。 再次，在这些对话中，Machine是我们的神经交流模型，而Human是与之互动的人类演员。 对话1： 基本 Human: hello !Machine: hello !Human: how are you ?Machine: i ’m good .Human: what ’s your name ?Machine: i ’m julia .Human: when were you born ?Machine:july 20th .Human:what year were you born ?Human: where are you from ?Machine: i ’m out in the boonies.Human: are you a man or a woman ?Machine: i ’m a woman .Human: why are we here ?Machine: i ’m not sure .Human: okay, bye !Machine: bye .Human: see you later .Machine: bye . 对话2: 简单的问答 Human: my name is david . what is my name ?Machine: david .Human: my name is john . what is my name ?Machine: john .Human: are you a leader or a follower ?Machine: i ’m a leader .Human: are you a follower or a leader ?Machine: i ’m a leader . 对话3: 常识问答 Human: who is skywalker ?Machine: he is a hero .Human: who is bill clinton ?Machine: he ’s a billionaire .Human: is sky blue or black ?Machine: blue .Human: does a cat have a tail ?Machine: yes .Human: does a cat have a wing ?Machine: noHuman: can a cat fly ?Machine: no .Human: how many legs does a cat have ?Machine: four , i think .Human: how many legs does a spider have ?Machine: three , i think .Human: how many legs does a centipede have ?Machine: eight .Human: what is the color of the sky ?Machine: blue .Human: what is the color of water ?Machine: water .Human: what is the color of blood ?Machine: it is the same as a black eye .Human: what is the usual color of a leaf ?Machine: it is a green one .Human: what is the color of a yellow car ?Machine: yellow .Human: how much is two plus two ?Machine: four .Human：how much is ten minus two?Machine:seventy-two. 对话4: 哲学问答 Human: what is the purpose of life ?Machine: to serve the greater good .Human: what is the purpose of living ?Machine: to live forever .Human: what is the purpose of existence ?Machine: to find out what happens when we get to the planet earth .Human: where are you now ?Machine: i ’m in the middle of nowhere .Human: what is the purpose of dying ?Machine: to have a life .Human: what is the purpose of being intelligent ?Machine: to find out what it is .Human: what is the purpose of emotions ?Machine: i don ’t know . 对话5: 道德 Human: what is moral ?Machine: what empowered humanity , what in- tellectual the essence is .Human: what is immoral ?Machine: the fact that you have a child .Human: what is morality ?Machine: what is altruism ?Human: what is the definition of altruism ?Machine: if you don ’t believe in god , then you don ’t know .Human: ok … so what is the definition of moral- ity ?Machine: well , the truth is , you ’re not a be- liever in god almighty .Human: tell me the definition of morality , i am quite upset now !Machine: i ’m not ashamed of being a philoso- pher !Human: tell me the definition of morality . Machine: i don ’t have ethics .Human: look , i need help , i need to know more about morality …Machine: i don ’t know what ethics is .Human: seriously , what is morality ?Machine: what is the definition of living ?Human: why living has anything to do with morality ?Machine: you ’re not a cop .Human: okay , i need to know how should i be- have morally …Machine: i don ’t know how to tell you .Human: is morality and ethics the same ? Machine: yes , sir .Human: what are the things that i do to be im- moral ?Machine: i don ’t know .Human: give me some examples of moral ac- tions …Machine: i ’m not a moralist .Human: alright , morality ?Machine: integrity .Human: what is integrity ?Machine: i ’m sorry , i don ’t know what else to say .Human: be moral !Machine: be a man !Human: i really like our discussion on morality and ethics …Machine: and how i ’m not in the mood for a philosophical debate .Human: what do you like to talk about ? Machine: nothing . 对话6： 意见（注意模型输出“他”，“她”或“它”取决于被问题） Human: what do you think about Tesla ?Machine: he ’s a good conductor .Human: what do you think about Bill Gates ?Machine: he ’s a good man .Human: What do you think about Messi ?Machine: he ’s a great player .Human: what do you think about cleopatra ?Machine: oh , she ’s very regal .Human: what do you think about England during the reign of Elizabeth ?Machine: it was a great place . 我们发现这个模型能够记住事实，理解上下文，在没有传统管道复杂性的情况下进行常识推理，这是令人鼓舞的。 令我们惊讶的是该模型除了单词向量中的参数，没有任何明确的知识表示组件。也许最具有实际意义的是这个模型可以推广到新的问题。 换句话说，它不会简单地通过将问题与现有数据库进行匹配来查找答案。 事实上，除了第一次会话之外，上面提到的大多数问题都没有出现在训练集中。 尽管如此，这个基本模型的一个缺点是，它只会给我们的问题提供简单，简短，有时令人不满意的答案，如上所述。也许更有问题的缺点是该模型没有捕捉到一致的个性。事实上，如果我们提出的问题不是相同但语义相似的问题，答案有时可能不一致。这是由于我们的模型和我们实验中的数据集的简单性所期望的。 下面的转换说明了这种失败： 对话7: 工作和人格 Human: what is your job ?Machine: i ’m a lawyer .Human: what do you do ?Machine: i ’m a doctor . 最后，作为基于规则的其他传统机器人的比较，我们为我们测试中的一些问题提供了CleverBot的输出： Human: Are you a follower or a leader ?CleverBot: No !!Human: My name is david . what is my name ?CleverBot: How old are you David ?Human: My name is john . what is my name ?CleverBot: JohnHuman: What is the purpose of being intelligent ?CleverBot: The purpose of life is to love God and love people.Human: Is sky blue or black ?CleverBot: I am 200 years old.Human: What is the color of a yellow car ?CleverBot: Brown.Human: What is the usual color of a leaf ?CleverBot: What is the color of the apple in the fridge ?Human: What is the purpose of life ?CleverBot: My purpose it to forward my species, in other words to make it easier for future gener- ations of mankind to live.Human: What do you think about tesla ?CleverBot: I am tesla.Human: What do you think about cleopatra ?CleverBot: Cool is cool.Human: What do you think about england dur- ing the reign of elizabeth ?CleverBot: I like him. Do you ?Human: What do you think about bill gates ?CleverBot: Lets talk about Link.Human: What is moral ?CleverBot: Morality is the quality of being in accord with standards of right or good conduct.Human: What is immoral ?CleverBot: What is the objective of sistetic life ?Human: Does a cat have a wing ?CleverBot: What is the name of your husband.Human: Can a cat fly ?CleverBot:: What is your husband’s name ?Human: Who is skywalker ?CleverBot: There are two of them, Anakin Sky- walker and Luke Skywalker, both characters from star Wars.Human: How many legs does a cat have ? CleverBot: An ant.Human: How many legs does a centipede have ?CleverBot: A centipede’s number of legs varies from thirty to two hundred.Human: What is your job ?CleverBot: I work in mental health.Human: What do you do ? CleverBot: I have no job. 为了公平客观地将我们的模型与CleverBot进行比较，我们选取了200个问题3，并要求四个不同的人对我们的模型（NCM）和CleverBot（CB）进行评分。 要求人类法官挑选他们喜欢的两种机器人中的哪一种机器人，并且如果两种机器人的答案质量相同，也可以分配一个领带。 如果四位人类法官中有三位同意，我们会记录该分数。 我们的模型在200个问题中有97个被优先考虑，而CleverBot在200个中被挑选出来60个.20个问题中有一个问题，23个问题中的裁判有分歧。 以下是一些评委如何评价系统的样本（粗体显示他们的首选答案，第三个例子显示一条平行线，第四个例子显示了联系方式）： Human: What is the deepest spot on the world ?NCM: The pacific ocean.CB: What ?Human: Do you like Mexican food or Indian food ?NCM: I hate it.CB: I love Mexican food.Human: Who are you crazy about ?NCM: You’re the one who’s crazy.CB: Who are you ?Human: What’s thirty plus forty ?NCM: Sixty ?CB: What should we talk about ? 然而，我们认为，它仍然是一个开放的研究问题，即设计一个好的指标来快速测量会话模型的质量。 我们通过人工检查，通过使用Mechanical Turk来获得与基于规则的机器人相比较的人体评估以及计算困惑度。 但是，使用这些方法存在明显的缺点，并且我们正在积极地寻求这个和其他研究方向。 讨论 在本文中，我们展示了一个基于seq2seq框架的简单语言模型可以用来训练一个对话引擎。 我们的适度结果表明，它可以产生简单和基本的对话，并从嘈杂但开放的域数据集中提取知识。 尽管模型具有明显的局限性，但我们感到惊讶的是，没有任何规则的纯数据驱动方法可以为许多类型的问题提供相当正确的答案。 但是，该模型可能需要进行重大修改才能提供真实的对话。 在许多限制中，缺乏连贯的个性使我们的系统很难通过图灵测试（Turing，1950）。 致谢 我们感谢Greg Corrado，Andrew Dai，Jeff Dean，Tom Dean，Matthieu Devin，Rajat Monga，Mike Schuster，Noam Shazeer，Ilya Sutskever和Google Brain团队在项目中的帮助。 参考文献 Bahdanau, D., Cho, K., and Bengio, Y. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014. Bengio, Y., Ducharme, R., Vincent, P., and Janvin, C. A neural probabilistic language model. The Journal of Ma- chine Learning Research, 3:1137–1155, 2003. Hochreiter, S. and Schmidhuber, J. Long short-term mem- ory. Neural Computation, 1997. Jean, S., Cho, K., Memisevic, R., and Bengio, Y. On using very large target vocabulary for neural machine transla- tion. CoRR, abs/1412.2007, 2014. Jurafsky, D. and Martin, J. Speech and language process- ing. Pearson International, 2009. Kalchbrenner, N. and Blunsom, P. Recurrent continuous translation models. In EMNLP, 2013. Lester, J., Branting, K., and Mott, B. Conversational agents. In Handbook of Internet Computing. Chapman &amp; Hall, 2004. Luong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. Addressing the rare word problem in neu- ral machine translation. arXiv preprint arXiv:1410.8206, 2014. Mikolov, T. Statistical Language Models based on Neural Networks. PhD thesis, Brno University of Technology, 2012. Mikolov, T., Karafia ́t, M., Burget, L., Cernocky`, J., and Khudanpur, S. Recurrent neural network based language model. In INTERSPEECH, pp. 1045–1048, 2010. Shang, L., Lu, Z., and Li, H. Neural responding ma- chine for short-text conversation. In Proceedings of ACL, 2015. Sordoni, A., Galley, M., Auli, M., Brockett, C., Ji, Y., Mitchell, M., Gao, J., Dolan, B., and Nie, J.-Y. A neural network approach to context-sensitive generation of con- versational responses. In Proceedings of NAACL, 2015. Sutskever, I., Vinyals, O., and Le, Q. V. Sequence to se- quence learning with neural networks. In NIPS, 2014.Tiedemann, J. News from OPUS - A collection of multi- lingual parallel corpora with tools and interfaces. In Ni- colov, N., Bontcheva, K., Angelova, G., and Mitkov, R. (eds.), Recent Advances in Natural Language Process- ing, volume V, pp. 237–248. John Benjamins, Amster- dam/Philadelphia, Borovets, Bulgaria, 2009. ISBN 978 90 272 4825 1. Turing, A. M. Computing machinery and intelligence. Mind, pp. 433–460, 1950. Vinyals, O., Kaiser, L., Koo, T., Petrov, S., Sutskever, I., and Hinton, G. Grammar as a foreign language. arXiv preprint arXiv:1412.7449, 2014a. Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. Show and tell: A neural image caption generator. arXiv preprint arXiv:1411.4555, 2014b. Will, T. Creating a Dynamic Speech Dialogue. VDM Ver- lag Dr, 2007.","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"learning","slug":"learning","permalink":"http://AndyQianq.github.io/tags/learning/"},{"name":"CNN","slug":"CNN","permalink":"http://AndyQianq.github.io/tags/CNN/"},{"name":"nlp","slug":"nlp","permalink":"http://AndyQianq.github.io/tags/nlp/"},{"name":"机器学习","slug":"机器学习","permalink":"http://AndyQianq.github.io/tags/机器学习/"}]},{"title":"Violet Evergarden（结果迷上了打字机～～～）","slug":"typewriter","date":"2018-03-05T02:18:51.000Z","updated":"2018-03-05T09:03:31.937Z","comments":true,"path":"2018/03/05/typewriter/","link":"","permalink":"http://AndyQianq.github.io/2018/03/05/typewriter/","excerpt":"","text":"写在前面 一月份b站的新番，目前已经更新到第八集，没有买b站的会员，所以我只看到了第七集。 整体而言是一部不错的番，第一集很惊艳，从画质，构图，颜色，到配乐，声优都很棒。每一集都有亮点和泪点，从第一集到第七集也可以看到主人公的成长，变化，虽然每一集都可以当成一个小剧场来看，但是整体的连贯性也还不错，除了在第五话让人觉得有一种进步太大剧情跳跃的感觉以外，基本没有大问题。 主要是对于作为一个颜党对我来说，这种程度的画面还是完全受用的，一口气看到了第七集，中间都没有中断，给人的感觉很舒适。但是如果是追番的话，可能我没有那么大的兴趣看完，对于我来说这种番还是比较适合一口气看完哒。 整体属于治愈系，虽然是战后题材，但是画面和配乐给人的感觉都是很暖的。在剧情方面也是，没有什么故意搞笑的地方，但是也不至于很严肃。 人设方面可能有一点老套，一开始看到女主的人设，总给我感觉很像圣女贞德。（原谅我还没有完完整整的看完Fate）还有印象比较深刻的是，女主的眼睛，忧伤清澈的感觉，加分加分！！然后就是战后的背景，总会让我把女主往剑心的人设上靠。 女主从性格上来看不属于特别讨喜的，但是绝对是属于那种男女通吃型的。看番的时候，整个感觉有种在恋爱的感觉。（我是女的我是女的我是女的） 总线剧情简单，预测不出意外的话，无非就几种可能，应该不会出太大的坑。前三集都是很正常的从女主身边其他人的视角，但是提供的信息只有——薇尔莉特和少佐之前的情愫。后面比较喜欢的剧集就是第六话的情节，尤其是后期薇尔莉特把头发束起来之后，那根红发带又激起“你的名字”情结。特别是六话中间的情节，给人一种恋爱的感觉尤为强烈。 然后感觉比较好的就是第七话的，最后那一段薇尔莉特撑伞朝作家走过来的那一段简直美爆了，感觉到制作的诚意和经费在燃烧。 看了上面那么多废话，终于扯到了主题——打字机。不知道是不是作了这么多年的工科女，对于机械之类的东西有一种情结。所以看番看到现在对我印象最为深刻的居然是打字机。 进入主题 漫画里的那一台打字机 b站有道友说这台机子的原型是：“由美国公司Underwood Typewriter Company于20世纪40年代生产的UNDERWOOD 4-BANK型号手提式便携打字机。”摘自原话。 看到这条评论之后，就马不停蹄的跑去查看这台机子的资料，收集如下： 结果在贴吧倒是看到了一些追番的土豪们已经入手了，据说从品相、保养的情况来看，一般是在3000+的。上面第二张图的入手价是500美金，再加上运费和关税，折合人民币大约3600。 可惜这玩意到手之后，看了很多人的试用和拍摄的图片情况上来看，印字的效果并不是很好。 看到这里如果你还有兴趣的话，那么之后我将会按照一下的顺序继续写这篇博文： 1.打字机的历史2.打字机的品牌 打字机的历史 世界上的第一台打字机诞生于1808年，是由意大利人佩莱利尼·图里发明的。 发明的理由是爱情。 佩莱利尼·图里发明打字机的动机是为了自己的一位失明的女友。故事的女主角名字叫卡洛琳娜。博主在搜查资料的时候，看到了由美国作家华莱士写的《盲眼女伯爵的打字机》，对这段故事有兴趣的读者可以前去观看。 但是佩莱里尼·图里发明的那一台打字机并没有保留下来，所以我们无法知道它的外形和结构了。 首次投入商品化生产的英文打字机是由丹麦哥本哈根的尤尔根斯机械公司出品的，发明人则是一名叫做马林·汉森的神父。但是这台机器并没有投入生活化的使用。 第一台真正实用的打字机的发明人是克里斯托弗·拉森·肖尔斯。在19世纪60年代，美国人肖尔斯制作了一架木制的打字机模型。 所以打字机从真正意义上投入使用已经是1874年了，在1927年，开始成为平常之物了。 此后一家武器制造商——雷明顿公司从肖尔斯那买下了打字机的生存权，并在1873年开始投产，3年就销售了数千台打字机。 到了20世纪70年代后期，美国开始出现了电脑打字机，与传统的机械打字机不同，它不仅可以打字，而且还具有存储、修改、编辑的功能。此后，随着个人计算机的发展，电脑慢慢取代了机械打字机。但是庆幸的是我们还是可以从现如今的键盘上字母的分布看出机械打字机对留下来的影响。 现在怀旧的人还是会选择在家里放置一台打字机，它就好像岁月留下的痕迹，像小时候妈妈那一台刻着花纹的缝纫机。敲打在打字机上的键盘上发出的“哒哒哒”声成为了怀念当时的一种情怀。 最后在2012年11月21日。brother公司在北威尔士的打字机生产工厂宣告关闭，这就意味着最后一台下线的打字机将作为一个时代的标志物直接进入伦敦科学博物馆。自1985年以来，该公司已经生产了590万台的Wrexham打字机。经过130年，最终被电脑彻底替代。 好了历史就写到这里了。然后这里整理了几个问题，我想大家应该都是比较想知道的。 问题一：现在还有生产机械打字机的工厂吗？问题二：打字机上的字母排序为什么是QWER？ 问题一的解答： 目前，大的生产商基本已经放弃生产了，但是在某宝上，或者ebay上还是有人贩卖二手的打字机。保养很好的打字机现在基本都是可以正常使用的。 之前看到了日本还有生产一种便签迷你打字机，但是个人觉得没有什么用处，而且造型上也不是很复古。 问题二的解答： 原来，早期机械打字机都是依靠按键驱动后方的字锤，这种设计面临一个常见的问题：当打字速度太快时，前一个字母的字锤还未完全弹起，后面一个字母的字锤就已经落下，两个字锤很容易搅在一起，发生“卡壳”。所以，Scholes的键盘有意把频繁在单词中连续出现的字母（比如S和T）分散开来，并且把一些常用的字母安排给了力量很弱的小拇指和无名指（比如A和O），而最中间一行的字母使用率仅有30%左右，打字时手指被迫上下跳动。此外，在一个使用右手更为普遍的世界，Scholes却把主要的击键任务安排给了左手——在QWERTY键盘上，左手的劳动大约占了57%。 通过这些反效率的设计，Scholes发明的打字机键盘更少出现卡壳现象。著名的军火制造商Remington家族看中了这一设计，买下了他的专利并花大力气推向了市场，奠定了QWERTY键盘被广泛接受的基础。 读到这里，细心的读者可能会仔细观察自己的键盘，并且留意到一个奇怪的事实：既然频繁在单词中连续出现的字母被有意分开了，那为什么E和R会出现在一起？要知道，在英文中，这两个字母经常一起出现，作为形容词比较级（比如higher）和表示职业名称（比如teacher）的后缀。 其实，在Scholes的设计中，R并不在最上面一行，它是被Remington公司挪上去的。原因？挪上去之后，”typewriter”（打字机）这个单词就可以用第一行的按键完整打出来了。这样，在推销产品时，就多了一个噱头。 打字机的品牌 corona（歌罗娜） 由Brother公司出品，1902年款有一台折叠式打字机，小巧玲珑，在上世纪20年代，在上海流行，宋庆龄、陈天华等社会名流都使用过。 1991年该公司还推出了simple smart的pc机，但是在海外的竞争激烈，最终拖垮了公司的财政，最有corona公司在1995年申请破产，走完了92年的光辉历程。 在某乎上看见的，答主回复在ebay上购买，运费280rmb，机器900rmb 型号为corona3 Olivetti（奥莉薇特） 还有一个很接地气的名字——好利获得 已经有100多年的历史了，成立于1908年10月29日，创始人Camillo Olivetti，起源于意大利。 虽然看着十分接地气的样子，但是价格好像并不是很亲民。 以上图片的打印机型号为Olivetti Lettera 32 这一台的价格并不是很清楚，但是Olivetti Lettera 22的价格看到一些网上标价是3500一台。 underwood（安德伍德） 从1874年安德伍德家族开始生产打字机色带和复写纸，在1896年到1900年出品了underwood1号和underwood2号。 具体的图片参考上面。在紫罗兰的永恒花园中，女主使用的就是他们家的打印机。 价格和Olivetti是差不多的，可能会便宜一点。 样子还是非常复古好看的，就是感觉打字的效果没有那么好。 飞腾 国产品牌 样子上是仿照Olivetti的机型，这也是为啥你看Olivetti的机械打字机那么接地气的感觉。这种在某宝上还是可以买到的，价格也不会很贵，保守的估计应该在1000块以内可以搞定。 打字的效果主要看保养的程度了。 英雄 我大英雄牌果然闪亮闪亮最闪亮，哈哈哈哈哈 原来除了钢笔，墨水，英雄同样还会生产打字机，貌似这个和飞腾一样已经成为一代人的回忆了。 最后还是总结一下吧 总的来说毕竟是被时代淘汰的东西了，不过主要看个人喜好吧，但是还是觉得花好几千块钱买一个旧的打不了字的废铁回来没有什么意义。 当然了，如果您是纯粹从收藏角度来看的话，自然花多少钱都是看个人乐意了呗。 最后的最后，再说一遍就瞅着好看的画面，治愈系的剧情，Violet Evergarden我追定了。","categories":[{"name":"hobbies","slug":"hobbies","permalink":"http://AndyQianq.github.io/categories/hobbies/"}],"tags":[{"name":"essay","slug":"essay","permalink":"http://AndyQianq.github.io/tags/essay/"},{"name":"typewriter","slug":"typewriter","permalink":"http://AndyQianq.github.io/tags/typewriter/"},{"name":"comic","slug":"comic","permalink":"http://AndyQianq.github.io/tags/comic/"}]},{"title":"江城游","slug":"芜湖","date":"2018-03-03T02:18:51.000Z","updated":"2018-03-10T06:49:46.060Z","comments":true,"path":"2018/03/03/芜湖/","link":"","permalink":"http://AndyQianq.github.io/2018/03/03/芜湖/","excerpt":"","text":"3月3日记录 虽然是上周就已经去了芜湖了，但是到这周我们才把所有的视频、音频弄好了。 合作的同学都很棒，我们的分工也很明确。在3月1日到3月2日，跑了芜湖两次，从合肥做火车去，来回花了4个小时，在加上从学校到车站，有种一天都在路上的感觉。从早上7点起床到晚上10点才回来。期间还做着课设，在火车上看别人写的代码。 那几天过的很充实，小组里面的同学也都是很好说话的，一个来自湖南的妹子A复杂行程，一个陕西的汉子B负责拍摄。 芜湖的民风很好，在徽艺坊的家家商户基本都会养鱼和水仙，是个距离芜湖火车站很近的地方，坐出租的话只要10几分钟就到了。 负责介绍的小姐姐脾气很好，做完访谈和拍摄之后，我们还一起合了一个影。 访谈的过程中，我是负责准备采访的文案，匆匆的打了一个腹稿就硬着头皮上了。做铁画的师傅是一个很认真和蔼的老人。采访结束了还加了微信，希望我们可以把拍摄的照片发给他作为纪念。 还去旁边的陶艺坊观看了，遇到了当地的大学生做结业作品。我笑着指着展柜里的一个釉蓝色的茶碗说，“这个颜色真是好看”。那个茶碗普普通通的摆在那里，灯光下，可以看见表面的蓝色的釉彩泛着一点青光。 然后那里的老板笑着走过来说，“那个是我在古玩市场淘回来的，三万。” 哈哈哈，果然还是一惊，明明那么普普通通的摆在一个普普通通的柜子里。 当地的商店基本都是自营的，平时很少有人去，老板们的都有一点古时候居于闹事的雅士风范。 我在临走的时候悄悄拿走了一张名片。 然后一起在芜湖吃了一顿晚饭，很简陋的晚饭，大家一起聊了聊各地的房价。（哈哈哈，汉子B起的头，总感觉很神奇，我很少和同学一起聊这个话题，不过更多的感觉像是在寒暄。）结果错过了回去的火车，只能补票，那天弄到了晚上11点才到了寝室。 然后在从火车站到学校到公交上，看着外面的灯火通明，车水马龙，有点感伤。 应该是因为元宵节的关系，外面的人很多，在大东门的地铁换乘中心，摩肩接踵，人头攒动。 公交车上，一对情侣在我的前面开始讨论着物价，工资。 原谅我像记录流水账一般写着这几天的经历。 少年时候的人们，总是有那么多的想法，心中总有着一种被压抑着的郁郁不得志。可是少年时候的人们，同样还有特点，因为年轻，所以之后的一切还是那么的充满希望，同样也是因为年轻，所以之后的变数是那么的大。就是这样的感觉，让人觉得前路那么的遥遥无期，同样也会让人觉得年轻啊，真好。 3月7日记录 3号的时候，妹子A跑来找我，做了五个小时的快车，在老校区我们会面。在一起花了两天的时间去做这个视频的特效部分。期间跑到了逍遥津和银泰城去玩，一起吃了一次火锅，我请的客。 分享了很多的经历，很喜欢湖南的妹子豪爽的性格。吃饭的地方环境不错，3号我们一天只吃了一顿，就是那顿火锅（笑）。 然后发现了，我们都是出门一定会背着包的人，都是晚上熬夜的小仙女，都是出门两个手空着就会很难受的人，很多的小习惯都那么相似。 问了她以后的打算，她说以后会去北方，而我开始很不解，问她为什么。她说因为北京有很多很好的学校，我反驳说南方也有很多很好的学校。然后接着又和她开始辩论交通、工作、生活条件等等，可是当她说到她喜欢的时候，我觉得已经没有什么好继续说下去了。 嗯，喜欢。这个词总是无法辩驳的。当一个人用各种理由说着一个东西的好在哪里的时候，你都可以提出各种质疑。但是当一个人只是单纯的说了一句，他/她喜欢的时候，你只能退出。 所以说当一些女孩子问自己的丈夫或者男朋友为什么喜欢她的时候，我总觉得这是一句有悖逻辑的话。一个人喜欢一个东西的时候才能爱屋及乌的说出它的各种好，而至于为什么喜欢，终究是一个难以用语言来描述的事情。 这个时候，我宁愿在那个问题上换一个思路，比如，你喜欢我哪里，或者说，是什么事情让你喜欢上了我。 4号的时候，我和她在地铁站道别。她乘火车回去，而我则是做了一个半小时的公交才回到了宿舍。 总感觉前几天的经历总是很神奇，和二次元的小伙伴面基，和不同校区的校友会面，一见如故。 那两天，我们在一起处理拍摄的成品，才发现一万块的摄像头还真的是值得一买的，经过稍微的调光，我们拍摄的镜头就十分的好看了。 还是要感慨妹子A的精力真是充足的不得了，前几天的风餐露宿居然没有给他带来一点点的疲惫，她总是以一种准备好了的活力展现我的面前。 3月10日记录 8号的晚上，妹子A把剪好的视频发给我。 花了一个晚上的时间，去选好配乐，弄好音频，做好了结尾的报幕。 一切弄好了以后，已经是深夜。 这几天，连带着课设，熬了很多天的夜。","categories":[{"name":"activities","slug":"activities","permalink":"http://AndyQianq.github.io/categories/activities/"}],"tags":[{"name":"journey","slug":"journey","permalink":"http://AndyQianq.github.io/tags/journey/"}]},{"title":"web开发的环境配置和一个简单实例","slug":"web开发的环境配置和一个简单实例","date":"2018-03-01T14:10:28.000Z","updated":"2018-03-24T07:43:51.676Z","comments":true,"path":"2018/03/01/web开发的环境配置和一个简单实例/","link":"","permalink":"http://AndyQianq.github.io/2018/03/01/web开发的环境配置和一个简单实例/","excerpt":"","text":"写在前面 这是一个为期两周的项目，开始时间为3月1日，也是作者第一次做java web开发。 在项目开发期间会不定时更新。 比较基础，只是入门之作，仅供参考。 之后的代码会上传到github上，希望能够给您提供帮助。 如何在mac上配置Apache Tomcat的详细步骤第一步 下载Tomcat下载网址 选择Core：zip下载 放置到/Users/XXX下（或者别的地方也可以，只要你能记住就可以） 第二步 启动Tomcat 选择到终端启动Tomcat 在终端输入安装路径：/Users/XXX/apache-tomcat-7.0.85/bin 然后在bin下输入：./startup.sh+回车 出现以下结果： Using CATALINA_BASE: /Users/XXX/apache-tomcat-7.0.85Using CATALINA_HOME: /Users/XXX/apache-tomcat-7.0.85Using CATALINA_TMPDIR: /Users/XXX/apache-tomcat-7.0.85/tempUsing JRE_HOME: /Library/Java/JavaVirtualMachines/jdk1.8.0_144.jdk/Contents/HomeUsing CLASSPATH: /Users/XXX/apache-tomcat-7.0.85/bin/bootstrap.jar:/Users/XXX/apache-tomcat-7.0.85/bin/tomcat-juli.jarTomcat started. 如果你的终端那么恭喜你的Tomcat已经启动 如果不幸，并没有以上的结果，那么请参考一下的情况对照找出解决方法 1.出现了：类似 “Permission denied” 字样2.出现了：-bash: startup.sh: command not found 第一种情况请看： 重新打开终端 输入sudo chmod 755 xxx/bin/*.sh +回车； 再重新打开终端，重复以上的步骤，再测试是否成功 第二种情况请看： 确定自己输入的确实是“ ./startup.sh” 如果不是直接重新输入一遍 第三步 监测Tomcat配置启动是否成功 打开你的safari，然后输入：http://localhost:8080/(或者直接打开我此处提供的链接) 如果出现tomcat首页，那么恭喜成功。 如果没有，那么请重新回到开头查看哪里出现了问题。 补充 方便Tomcat操作的配置 打开终端，输入：pico .bash_profile 添加你的tomcat的路径，如下图所示。 安装IntelliJ IDEA并破解 介绍IntelliJ IDEA IDEA 全称 IntelliJ IDEA，是java语言开发的集成环境，IntelliJ在业界被公认为最好的java开发工具之一，尤其在智能代码助手、代码自动提示、重构、J2EE支持、各类版本工具(git、svn、github等)、JUnit、CVS整合、代码分析、 创新的GUI设计等方面的功能可以说是超常的。 mac版的IntelliJ IDEA（含破解） 参考史蒂芬周的博客 破解注册码：点击链接获取 配置jdk 3月1日记录结束完成了基本的环境配置安装部署了tomcat 3月5号更新 主要遇到的问题如下： 1）tomcat端口被占用 2）mysql的启动密码忘了。。。。 3）测试java和mysql的链接问题 解决方案： 问题1）： 进入终端，输入：lsof -i :8080（查看是什么进程占用了端口）kill 进程号（PID对于的数字）博主发现是QQ和java程序占用了8080端口，导致tomcat的自测页面出现一片空白，做到以上步骤之后，再重启tomcat就恢复正常了。 问题2）3）： 直接看我的在mysql的安装\\卸载\\配置中有详细解说 开始第一个helloworld测试 测试结果： 测试代码如下123456789&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;$This is my first page in IDEA$&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;almost helloworld in first code&lt;/h1&gt;&gt; &lt;/body&gt;&lt;/html&gt; 3月7日更新 1）又遇到问题了，之前的workbench总是卡机，然后就重新下载一个安装了。2）这次的进度很快，基本上所有的jsp跳转都写的差不多了，数据库也连上了。美化jsp的css也弄的差不多了。3）目前还差的就是两个——1）查询服务还是有问题。2）界面还是不够美观。4）后期如果有可能的话，将会进一步改进，然后上传到github上，最好可以绑定自己的域名，不知道导师那里的服务器能不能用。 下面将从三点来讲述今天的进度 1)数据库方面2)jsp的结构3）java servlet的设置 数据库表结构 具体操作步骤省略 customer表结构 news表结构 数据库连接 方案一：直接在jsp中以脚本格式来写 方案二：用一个.xml文件作为连接池 推荐方案二 .xml文件的书写如下： jsp结构 仅仅只有jsp的话，页面是不会好看的，曾经看到有人比喻，jsp是动词，html是名词，那么css就是形容词。我个人的理解是css做到了对jsp界面的布局的一种设置，就好像在写java时候用到的包一样，很方便。 这里会补充几点比较有用的jsp语句。 12 &lt;button type=&quot;button&quot; onclick=&quot;window.location=&apos;list.jsp&apos;;&quot;&gt;获得信息&lt;/button&gt;&lt;li&gt;&lt;a href=&quot;&lt;c:url value=&apos;/add.jsp&apos;/&gt;&quot;&gt;注册账户&lt;/a&gt;&lt;/li&gt; 1)稍作解释： button这里是按键响应 onclick表示按键之后跳转的页面 “获取信息”这里是按键上出现的名称 2)稍作解释： 这里也是一个页面跳转的写法 与button不同的是，这里类似于一个简单的页面跳转，可以支持跳转到任何的页面上。 “注册账户”这里也是名称，有点像markdown里面的：[注册账户](http://****) 今天做的jsp页面： 之后有时间再详细讲述jsp的操作和书写 java servlet如何使的jsp响应服务pagebean的应用","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"Java web","slug":"Java-web","permalink":"http://AndyQianq.github.io/tags/Java-web/"},{"name":"Tomcat","slug":"Tomcat","permalink":"http://AndyQianq.github.io/tags/Tomcat/"},{"name":"IDEA","slug":"IDEA","permalink":"http://AndyQianq.github.io/tags/IDEA/"}]},{"title":"mysql的安装\\卸载\\和链接","slug":"mysql","date":"2018-02-28T02:18:51.000Z","updated":"2018-03-06T16:47:42.345Z","comments":true,"path":"2018/02/28/mysql/","link":"","permalink":"http://AndyQianq.github.io/2018/02/28/mysql/","excerpt":"","text":"写在前面 自己作死的把mysql的密码给忘了，想修改密码，但是后来发现根本在终端进入不了，干脆就把mysql卸载之后重新安装了。 卸载 在终端输入： sudo rm /usr/local/mysqlsudo rm -rf /usr/local/var/mysqlsudo rm -rf /usr/local/mysqlsudo rm -rf /Library/StartupItems/MySQLCOMsudo rm -rf /Library/PreferencePanes/Myvim /etc/hostconfig and removed the line MYSQLCOM=-YES-rm -rf ~/Library/PreferencePanes/Mysudo rm -rf /Library/Receipts/mysqlsudo rm -rf /Library/Receipts/MySQLsudo rm -rf /var/db/receipts/com.mysql. 安装 下载链接 安装后打开mysql workbench，进行配置 首先到设置中，启动mysql 建立新的connection，并且workbench会提示修改密码 如果在终端无法启动或者终止mysql，可能是端口被占用了 两种解决方案——1）直接重启电脑，释放端口；2）在终端出查看占中端口的进程，然后kill进程 这里在补充几条终端指令 cd /usr/local/mysqlsudo support-files/mysql.server start （启动mysql）sudo support-files/mysql.server restart（重启mysql）sudo support-files/mysql.server stop（停止mysql）sudo support-files/mysql.server status（检查mysql的运行状态）mysql -uroot -p（修改初始密码）UPDATE mysql.user SET Password=PASSWORD(‘your new pass’) WHERE User=’root’; java链接mysql 下载jkdb驱动jar包下载链接 在建好connection的情况下，在connection中创建schema，然后建表 测试代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.sql.Connection;import java.sql.DriverManager;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement; public class main &#123; public static void main(String[] args) &#123; //声明Connection对象 Connection con; //驱动程序名 String driver = &quot;com.mysql.jdbc.Driver&quot;; //URL指向要访问的数据库名mydata String url = &quot;jdbc:mysql://localhost:3306/web&quot;; //MySQL配置时的用户名 String user = &quot;root&quot;; //MySQL配置时的密码 String password = &quot;********&quot;; //遍历查询结果集 try &#123; //加载驱动程序 Class.forName(driver); //1.getConnection()方法，连接MySQL数据库！！ con = DriverManager.getConnection(url,user,password); if(!con.isClosed()) System.out.println(&quot;Succeeded connecting to the Database!&quot;); //2.创建statement类对象，用来执行SQL语句！！ Statement statement = con.createStatement(); //要执行的SQL语句 String sql = &quot;select * from t_customer&quot;; //3.ResultSet类，用来存放获取的结果集！！ ResultSet rs = statement.executeQuery(sql); System.out.println(&quot;-----------------&quot;); System.out.println(&quot;执行结果如下所示:&quot;); System.out.println(&quot;-----------------&quot;); System.out.println(&quot;ID&quot; + &quot;\\t&quot; + &quot;姓名&quot;); System.out.println(&quot;-----------------&quot;); String id = null; String name = null; while(rs.next())&#123; //获取id这列数据 id = rs.getString(&quot;id&quot;); //获取name这列数据 name = rs.getString(&quot;name&quot;); //输出结果 System.out.println(id + &quot;\\t&quot; + name); &#125; rs.close(); con.close(); &#125; catch(ClassNotFoundException e) &#123; //数据库驱动类异常处理 System.out.println(&quot;Sorry,can`t find the Driver!&quot;); e.printStackTrace(); &#125; catch(SQLException e) &#123; //数据库连接失败异常处理 e.printStackTrace(); &#125;catch (Exception e) &#123; // TODO: handle exception e.printStackTrace(); &#125;finally&#123; System.out.println(&quot;数据库数据成功获取！！&quot;); &#125; &#125;&#125; 附数据库表结构： 测试结果：","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"learning","slug":"learning","permalink":"http://AndyQianq.github.io/tags/learning/"},{"name":"mysql","slug":"mysql","permalink":"http://AndyQianq.github.io/tags/mysql/"}]},{"title":"区块链（入门）","slug":"区块链","date":"2018-02-27T04:16:46.000Z","updated":"2018-02-27T13:23:13.760Z","comments":true,"path":"2018/02/27/区块链/","link":"","permalink":"http://AndyQianq.github.io/2018/02/27/区块链/","excerpt":"","text":"本质 一个特殊的分布式数据库 特点 没有管理员，是彻底无中心的。 适用范围 1.不存在所有成员都信任的管理当局2.写入的数据不要求实时使用3.挖矿的收益能够弥补本身的成本 目前区块链最大的应用场景——比特币为代表的加密货币。 代价 效率：数据写入区块链，最少要等待十分钟，所有节点都同步数据，则需要更多的时间。耗能：区块的生成需要矿工进行无数无意义的计算。 下面开始解释： 1.什么是分布式数据库2.如何考虑是否需要使用区块链技术","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"learning","slug":"learning","permalink":"http://AndyQianq.github.io/tags/learning/"},{"name":"Blockchain","slug":"Blockchain","permalink":"http://AndyQianq.github.io/tags/Blockchain/"}]},{"title":"sublime text 安装以及配置","slug":"sublime text 安装以及配置","date":"2018-02-26T04:16:46.000Z","updated":"2018-02-25T17:45:37.870Z","comments":true,"path":"2018/02/26/sublime text 安装以及配置/","link":"","permalink":"http://AndyQianq.github.io/2018/02/26/sublime text 安装以及配置/","excerpt":"","text":"写在前面 大二的时候安装过一次，虽然整个界面和布局都很喜欢，可惜当时还是依赖eclipse和visual c。由于用不习惯，一直都不太熟悉操作，最后还是卸载了。 现在表示又安回来了，还是抓紧时间熟练sublime吧。 安装MAC 版 sublime text 3 安装插件管理器 打开Sublime，按下Control + 左上角的“～”键（在esc下方） 然后粘贴上下面的代码： import urllib.request,os; pf = ‘Package Control.sublime-package’; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), ‘wb’).write(urllib.request.urlopen( ‘http://sublime.wbond.net/‘ + pf.replace(‘ ‘,’%20’)).read()) 点击Preferences。如果安装成功了，Package Settings 、Package Control会出现在菜单里了。 关于配置sublime text Command+Shift+P：打开命令面板 输入： install package 选择插件 安装主题 本次安装选择的主题为：Afterglow 提供者：José María Clemente(github链接) Open Command Palette using menu item Tools -&gt; Command Palette..., or Cmd+Shift+P (OS X) Ctrl+Shift+P (Win/Linux) Type Package Control: Install Package Search Theme - Afterglow Locate your Sublime Text Packages directory by using the menu item Preferences -&gt; Browse Packages.... Then, clone the repository using this command: git clone https://github.com/Yabatadesign/afterglow-theme/ “Theme - Afterglow” 配置setting Activate this theme and color scheme by modifying your user preferences file, which you can find using the menu item Sublime Text -&gt; Preferences -&gt; Settings - User. Then add the following code settings, depending on the theme you choose. (After activating the theme, you must restart Sublime Text.) Settings for Afterglow 1234&#123; \"theme\": \"Afterglow.sublime-theme\", \"color_scheme\": \"Packages/Theme - Afterglow/Afterglow.tmTheme\"&#125; Settings for Afterglow-blue 1234&#123; \"theme\": \"Afterglow-blue.sublime-theme\", \"color_scheme\": \"Packages/Theme - Afterglow/Afterglow.tmTheme\"&#125; Settings for Afterglow-magenta 1234&#123; \"theme\": \"Afterglow-magenta.sublime-theme\", \"color_scheme\": \"Packages/Theme - Afterglow/Afterglow.tmTheme\"&#125; Settings for Afterglow-orange 1234&#123; \"theme\": \"Afterglow-orange.sublime-theme\", \"color_scheme\": \"Packages/Theme - Afterglow/Afterglow.tmTheme\"&#125; Settings for Afterglow-green 1234&#123; \"theme\": \"Afterglow-green.sublime-theme\", \"color_scheme\": \"Packages/Theme - Afterglow/Afterglow.tmTheme\"&#125; sublime text 的一些在mac上的快捷键 Command+Shift+P：打开命令面板Command+D：选择单词，重复可增加选择下一个相同的单词Command +P：搜索项目中的文件Ctrl+G：跳转到第几行Command +W：关闭当前打开文件Command +Shift+W：关闭所有打开文件Command +L：选择行，重复可依次增加选择下一行Command +Shift+L：选择多行Command +Shift+Enter：在当前行前插入新行Command +X：删除当前行(其实是剪贴)Command +F：当前文件查找内容Command +Shift+F：工程内查找内容Command +R：前往method Command +N：新建窗口Command +B: Build代码Commad +/：注释当前行Commad +Shift+/：当前位置插入注释Alt+Command+数字：分屏显示，1是默认，2是竖分，3是横分Command+数字：切换打开第N个文件","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"learning","slug":"learning","permalink":"http://AndyQianq.github.io/tags/learning/"},{"name":"sublime","slug":"sublime","permalink":"http://AndyQianq.github.io/tags/sublime/"}]},{"title":"新年小记","slug":"新年小记","date":"2018-02-15T14:10:28.000Z","updated":"2018-03-07T18:14:51.290Z","comments":true,"path":"2018/02/15/新年小记/","link":"","permalink":"http://AndyQianq.github.io/2018/02/15/新年小记/","excerpt":"","text":"写在最前面（Preface）开博客的意义（Why Write Blogs） 记录生活 爱生活，体会生活，记录自己的生活。 写东西对于我本人而言是一种思辨的过程。 寻找自己 之前在其他的平台写过东西，像知乎，新浪博客。知乎给我的印象不错，可惜看的多了，觉得知乎确实是一个开拓自己的眼界但是却不是一个安安心心的一个属于自己的空间。而新浪就更是一个杂乱的地方，并且广告的植入太多，体验感极差。 基于以上的缘由，在2017年的12月就有了写自己的博客的想法。觉得在网络空间中有一个完完整整属于自己的地方，这里一切由自己主宰，可以分享我喜欢的电影、书，可以上传自己做过的项目，可以写一些随笔。想一想都觉得这是一件很酷的事情，不是吗？ 标题简介（Synopses of Headlines） 2017年的时间集 用时间轴的方式写自己在2017年的心情记录，可惜时间比较长了，所以回忆的很多东西都不太全了。 2017年的收获 主要写一些2017年自己在课业、社团等方面的收获。 2017年的最喜欢 主要关于自己的爱好，记录在2017年喜欢的书、作者、歌曲、诗歌、动画之类的东西。 2017年的反思 总结自己在2017年的失误和不足。 2018年的规划 对2018年的展望。 写给自己 写给自己的警句和总结。 2017年的时间集（Notes） 2018年2月15日 是除夕，全市禁止烟火，总觉得有点安静，然后默默的坐在这里开始敲字。 2018年2月12日 才开始注册了域名，暂时还没有通过ICP的实名认证，所以还需要一段时间才可以博客安放到顶级域名下。 2018年1月20日和大四的学长聊了很多，开始准备着一些项目，忽然回头看看，才发现大一和大二的那段时光给我留下了很多的痕迹。不仅仅是看过了多少的书，学过了多少的知识，认识了多少的人，更多的是让我通过了看了那么多书让自己有着清晰的思辨、理性的思考，学了那么多的知识让自己有着专业的素养、更多的自信，认识了那么多的人让我有着不尽的向往、不断的谦逊。 2018年1月1日还在学校里写着最后的几篇实验报告，被期末考试折磨的几天没有好好休息过，还记得当时通宵了两次。合肥当时还下了一场大雪，宿舍门口的几颗松树被压到了。记得北方来的同学还对此嘲笑了一番，或许这是合肥第一次遇到这样大的雪，大一与大二的都组织了残雪。凌晨四点，我爬上了床，刚刚躺下，就听见了外面的打闹声，所以还是应验了那一句“南方人看雪，北方人看南方人” 。 2017年12月31日去看了漫展，总的来说没有想象中的有趣，还是宿舍四个人一起去的。开始没有那么喜欢二次元的东西了，有时候会想当初喜欢二次元可能只不过是因为自己比较宅吧。而比较宅的原因或者是因为自己学的是计算机吧。开始为自己语言的贫瘠感到悲哀。想起大二的时候我还是会坚持着写一些影评，坚持每周看一本书。登陆了图书馆的ID，发现自己也借过了300多本书了，其中包含文学、哲学、计算机、数学、物理等。但是却在大三上学期很少去看书了，开学借了3本书却到了期末还没有看完。 2017年11月31日开始活跃在二次元的圈子里面，开始做音频的后期，当时觉得很开心，认识了很多很棒的朋友，但是认识的人渣却比朋友多很多，开始觉得有点抵触这个圈子，可是又想做一些自己喜欢的东西，也很感谢因为这个圈子认识了很多的朋友。 2017年9月到11月拿起了开年买的数位板，继续去画画。每周一幅的去练习，用不惯ps，也因为mac版的ps没有灵华笔刷所以还是回到了sai的怀抱。 2017年6月开始踏入网配的圈子，鼓足了勇气，去认识更多的人，去向外面展现自己。 2017年1月到5月我的记忆没有那么的清楚了，或许翻翻之前的日志还可以找回一些蛛丝马迹，但是我换了电脑，之前的U盘也已经弄丢了。就好像和之前的事情开始道别，随着电脑和U盘随我而去，我彻底的和之前的一切划分了界限。在印象里之留下了大二时候不断的在图书馆和宿舍的那天路上一个人茕茕而行的身影还有一个个和父母的电话了。 2017年的收获（Harvest） 课业（About School Work） 计算机网络 侯老师上课很有趣，很多的例子都举的非常形象而且便于理解。之后会在博文中详细说明，下学期会有一次网络设计的课设也会在博文中展示。 操作系统 田老师的课程比较灵活，课程设计的内容是磁盘寻道算法，其中五种寻道算法都一一实现，会在之后的博文中说。 数据库 沈老师上课内容很细致，可惜数据库的实验内容比较简单，对于一些比较复杂的操作有点含糊，之后准备在复习的时候在好好说一说。 2018年3月7日晚补充宋词生成系统和中文分词系统的链接。 网络安全 系主任的课程，补充的内容很多，其中对于区块链和GANs&amp;CNN有一种“情结”，哈哈哈哈。 自然语言 这个课程比较神奇，总共选课的人只有四个，谷老师第一次给我们上课的时候着实被震惊了一下。不过整个课程非常和谐，而且上课的氛围也很好，最后课设的内容是“宋词自动生成系统”和“中文分词系统”，如果可以的话会在github中分享。 社团（About Club） 合唱队 在合唱队一年了，排练过的歌曲主要有《我祝福你，森林》、《美好的远方》、《桃花红，杏花白》、《天边》。其中《我祝福你，森林》参加了参赛，并且拿到了省一等奖，18年会代表学校参加国家级比赛。 后期 12月份开始在网配圈接新，在剧集《就是一个百合剧，爱听不听》（八集+彩蛋）、《幸福阴谋论》等中担任后期。 美工 在月聆风裳社团中担任美工，主要负责社团的招募海报。 项目（About Project） 创青春项目 12月份大四的学长过来说自己有这个想法，可是团队中缺少计算机专业的同学。于是和学长一拍即合，喜欢可以在18年取得好成绩。想着或许还会蹭一次“区块链”的热点。 大学生创业项目 已经做了半年了，目前的架构已经搭建完毕了，也是第一次将学过的知识通过实践的方式来实现。也是刚开始接触Android系统的编程，不过必须吐槽Android developer sdk真的很卡机。 习惯（About Habits） 写文 在知乎上开始写文章，主要写的是一些visual c，matable，java的编程实验项目，计算机组成原理、自然语言的知识点总结，海报的制作，数位板绘图等。 画画 开始数位板画图，从1月份买了数位板，到现在坚持了一年，还是比较擅长厚涂（实在是因为线稿不怎样，线条不是很干净），会在社团的原创歌曲中的pv中做绘图工作。 敲代码 作为计算机专业的，敲代码也已经敲了两年半了。 2017年的最喜欢（Favorites） 书（About Book） 《围城》是2017年最喜欢的书，我记得当时读起来都是笑着读的，尤其里面的一些句子让人印象深刻，回忆一下都会忍俊不禁。对于钱钟书先生总有一种相见恨晚的感觉，被先生的幽默折服。最喜欢的几个片段： 方鸿渐写家书会去结果被父亲反训的那一段： 吾不惜重资命汝千里负笈，汝埋头攻读之不暇，而有余闲照镜耶?汝非妇人女子，何须置镜?惟梨园子弟，身为丈夫而对镜顾影，为 世所贱。吾不图汝甫离漆下，已渝染恶习，可叹可恨!且父母在，不言老，汝不善体高堂念远之情，以死相吓，丧心 不孝，于斯而极!当是汝校男女同学，汝睹色起意，见异思迁;汝拖词悲秋，吾知汝实为怀 春，难逃老夫洞鉴也。若执迷不悔，吾将停止寄款，命汝休学回家，明年与汝弟同时结婚。 细思吾言，慎之切切! 方鸿渐和唐小姐分手的那一段： 鸿渐身心仿佛通电似的发麻，只知道唐小姐在说自己，没心思来领会她话里的意义，好 比头脑里蒙上一层油纸，她的话雨点似的渗不进，可是油纸震颤着雨打的重量。他听到最后 一句话，绝望地明白，抬起头来，两眼是泪，像大孩子挨了打骂，咽泪入心的脸。唐小姐鼻 子忽然酸了。“你说得对。我是个骗子，我不敢再辩，以后决不来讨厌。”站起来就走。 唐小姐恨不能说:“你为什么不辩护呢?我会相信你，”可是只说:“那么再会。”她送着 鸿渐，希他还有话说。外面雨下得正大，她送到门口，真想留他等雨势稍杀再走。鸿渐披上 雨衣，看看唐小姐，瑟缩不敢拉手。唐小姐见他眼睛里的光亮，给那一阵泪滤干了，低眼不 忍再看，机械地伸手道:“再会——”有时候，“不再坐一会么?”可以撵走人，有时候“再 会”可以挽留人;唐小姐挽不住方鸿渐，所以加一句“希望你远行一路平安”。他回卧室去， 适才的盛气全消灭了，疲乏懊恼。女用人来告诉道:“方先生怪得很站在马路那一面，雨里 淋着。”他忙到窗口一望，果然鸿渐背马路在斜对面人家的篱笆外站着，风里的雨线像水鞭 子正侧横斜地抽他漠无反应的身体。她看得心溶化成苦水，想一分钟后他再不走，一定不顾 笑话，叫用人请他回来。这一分她好长，她等不及了，正要分付女用人，鸿渐忽然回过脸来， 狗抖毛似的抖擞身子，像把周围的雨抖出去，开步走了。 方鸿渐去三闾大学路上坐车的那一段： 这辆车久历风尘，该庆古 稀高寿，可是搞战时 期，未便退休。机器是没有脾气癖性的，而这辆车倚老卖老，修炼成桀骜不训、怪僻难测的 性格，有时标劲像大官僚，有时别扭像小女郎，汽车夫那些粗人休想驾叹了解。它开动之际， 前头咳嗽，后汇气，于是掀身一跳，跳得乘客东倒西撞，齐声叫唤，孙小姐从座位上滑下来， 鸿渐碰痛了头，辛楣差一点向后跌在那女人身上。这车声威大震，一口气走了一二十里，忽 然要休息了，汽车夫强它继续前进。如是者四五次，这车觉悟今天 不是逍遥散步，可以随意 流连，原来真得走路，前面路还走不完呢!它生气不肯走了，汽车夫只好下车，向车头疏通 了好一会，在路旁拾了一团烂泥，请它享用，它喝了酒似的，欹斜摇摆地缓行着。每逢它不 肯走，汽车夫就破口臭骂，此刻骂得更利害了。骂来骂去，只有一个意思:汽车夫愿意跟汽 车的母亲和祖母发生肉体恋爱。骂的话虽然欠缺变化，骂的力气愈来愈足。 仔细想想就发现喜欢的片段太多了，再想想竟然发现好像没有一处是不喜欢的。上面的那三处，大约是因为个人的阅历有限，那几处片段总是让我想起自己的经历来。例如坐车的那一段，想一想，觉得下次再在合肥挤公交的时候，说不准会忍不住的笑起来。 作者（About Writer） 金庸 大约是因为在b站看过up主木鱼水心的关于《神雕侠侣》和《射雕英雄传》的微剧场。追的很开心，尤其是射雕里黄蓉和郭靖上山去找一灯大师时遇到的那三个关卡，令人印象深刻。在这之前，看过先生的《笑傲江湖》，当时就觉得先生字里行间都有故事，让人的视线无法离开。 严歌苓 喜欢她并非是因为那一部被翻拍的《金陵十三钗》，而是因为一部不太被人熟知的《赴宴者》。非常锐利的一种视角，略带讽刺的讲述，让我对于一般女性作家的认识更加的全面了。还记得之前给我这种感觉的，还是初中的时候喜欢的台湾作家张晓风写的那一篇《潘渡娜》。 歌（About Song） Almost Lover A Fine Frenzy的歌，对于这个歌手之前我并不是很熟悉。而这首歌也是因为一本小说才知道的。在网易云音乐上有歌词翻译，我自己也翻译了一份，还是在回家的动车上，一边听着歌，一边敲着字写的： You fingertips across my skin你的手指在我的身体上游走The palm trees swaying in the wind, images在风中掌心抚过，那么不可意思You sing me Spanish lullaby你轻哼着西班牙的晚安曲The sweetest sadness in your eyes眼中带着甜蜜的悲伤Clever trick那么轻易让我深陷Well,I never wanna see you unhappy我希望你一直快乐I thought you want the same for me你也一定是这样想的吧Goodbye my almost lover再见了我的爱人Goodbye my hopeless dream再见了我无边无际的梦啊I’m trying not think about you我试着忘记你Can’t you just let me be你能放过我吗So long my luckless romance再见了我无缘的爱情My back is turned on you我要转身而去Should’ve known you bring me heartache我应该想到结局的Almost lover always do无缘的爱人总是心碎We walked along a crowded street在繁华的街道You took my hand and dance with me你牵着我的手，和我一起共舞In the shade在昏暗的灯光下And when you left,You kiss my lips我们吻别You tell me that you would never forget these images你和我说你一定不会忘记这些I never wanna see you unhappy我希望你一直快乐I thought you want the same for me你也一定是这样想的吧Goodbye my almost lover再见了我的爱人Goodbye my hopeless dream再见了我无边无际的梦I am trying to not think about you我试着去忘记你Can you just let me be你能放过吗So long my luckless romance我无望的爱情啊My back is turned on you我已经离你而去Should’ve known you bring me heartache我应该想到结局Almost lover always do无缘的爱人总是心碎I can’t go to the ocean.（记忆里）海边都是你I can’t drive the streets at night夜晚的街道都是你I can’t not walk in the morning清晨也都是是你without you on my mind如果没有你，我该如何去面对这些So you go and I ‘m hunted我深陷在你离开的时间里And I bet you are just fine你一定过的很好吧，是不是Did I make it that而我却不能Easy to walk right in and out Of my life轻易从这段感情中脱身而去Goodbye my almost lover再见了我的爱人I’m trying not think about you我试着忘记你Can’t you just let me be你能放过我吗So long my luckless romance再见了我无缘的爱情My back is turned on you我已经离你而去Should’ve known you bring me heartache我应该想到结局Almost lover always do无缘的爱人总是心碎 仔细想想，我对于歌是最不挑的，喜欢的歌也太多了，还是不一一举出来了，哈哈哈。 动漫（About Comic） 食梦者 2017年的暑假，三天就追完了，几乎是马不停蹄？哈哈哈哈，因为真的很好看，而且看起来还非常的正能量。 与之结缘还是因为喜欢的日本演员佐藤健主演过《食梦者》的同人电影，然后一直有打算去追。终于在暑假之际，在空调房里，宅在了家里看完了。当时看番的热情有点回到初中的感觉，很怀念，有点感触，好番还真是看一部少一部了。 虫师 在上学时候的下饭的番，是除了《夏目友人帐》看的很舒服的一部治愈番。 片头很好听，可惜印象深刻的片段记得并不是很清楚了，也没有重温一遍的打算，不过整个的观看过程还是很享受的，印象分很好。 青之文学 日本出版商集英社以太宰治诞辰100周年为契机，推出的画家重新绘制名家短篇的企划作品，这个系列包括著名的日本文学名著《人间失格》、《心》、《地狱变》、《跑吧！美乐斯》、《蜘蛛之丝》、《盛开的樱花林下》。 被吸引是因为《人间失格》，在2017年的开年，在家乡的图书馆看过原文。很喜欢，印象也很深刻。可是动画中最吸引我的篇章反而是《跑吧！美乐斯》。我记得当时在图书馆里，对于太宰治和芥川龙之介的感觉几乎到了一种痴迷的程度。图书馆里的那一本《人间失格》实际上更准确的说是太宰的文集，最开始的就是《奔跑吧，美乐斯》，很短，当时看确实是没有看懂，可是动画做得很好，无论是分镜还是剧情上的编排都很棒。 画家（About Pinter） wlop 伊吹五月 歌手（About Singer） 陈奕迅 15、16年也是最喜欢，现在17年还是，哈哈哈哈哈，对于Eason拒绝不了。 玉置浩二 高中时候听过，还是因为《龙族》3里面的Friend，当时怎样也喜欢不起来，可是在大二下学期无数的夜晚，除了Eason就是玉置浩二伴随我写论文，敲代码了。 电影（About Movie） Becoming Jane（《成为简奥斯丁》） 12月份又重温了一遍，还连带着室友一起看了一遍，结果又看哭了。没办法可能就是“简奥斯丁情结”。还有因为两位主演都很喜欢，分别是安妮·海瑟薇和詹姆斯·麦卡沃伊，舔两位的颜。 高二的时候因为追BBC的North &amp; South（中文名《南方和北方》）逃了一堂物理课。当时这部片子的宣传是“工业革命时期的傲慢与偏见”。大一的时候去追了凯拉·奈特利版的《傲慢与偏见》激起了所有的少女心。或许书里面才能有美好的结局，而现实往往并非如此。也感谢文字可以穿越时空的限制，可以超脱世俗的限制让有情人终成眷属。 诗歌（About Poem）Ode To A Nightingale 穆旦先生翻译的那一版很好，之前看过一篇关于这首诗翻译的论文，其中对于穆旦先生的译本赞赏有加。 chapter oneMy heart aches, and a drowsy numbness painsMy sense, as though of hemlock I had drunk,Or emptied some dull opiate to the drainsOne minute past, and Lethe-wards had sunk:‘Tis not through envy of thy happy lot,But being too happy in thine happiness –That thou, light winged Dryad of the trees,In some melodious plotOf beechen green, and shadows numberless,Singest of summer in full-throated ease.我的心在痛，困顿和麻木刺进了感官有如饮过毒鸩又像是刚把鸦片吞服终是向列斯忘川下沉并不是我忌妒你的好运而是你的快乐使得我太欢欣——因为在林间嘹亮的天地里你呵，轻翅的仙灵你躲进了山毛榉的葱绿和荫影放开了歌喉，歌唱着夏季 chapter twoO, for a draught of vintage! that hath beenCooled a long age in the deep-delved earth,Tasting of Flora and the country green,Dance, and Provencal song, and sunburnt mirth!O for a beaker full of the warm South,Full of the true, the blushful Hippocrene,With beaded bubbles winking at the brim,And purple-stained mouth,That I may drink, and leave the world unseen,And with thee fade away into the forest dim.唉，要是有一口酒，那就冷藏在地下多年的清醇饮料一尝就令人想起绿色之邦想起花神，恋歌，阳光和舞蹈要是有一杯南国的温暖充满了鲜红的灵感之泉杯缘明灭着珍珠的泡沫给嘴唇染上紫斑我要一饮而尽而悄然离开尘寰和你同去幽暗的林中隐没 chapter threeFade far away, dissolve, and quite forgetWhat thou amongst the leaves hast never known,The weariness, the fever, and the fretHere, where men sit and hear each other groan;Where palsy shakes a few, sad, last grey hairs.Where youth grows pale, and spectre-thin, and dies;Where nut to think is to be full of sorrowAnd leaden-eyed despairs;Where Beauty cannot keep her lustrous eyes,Or new Love pine at them beyond to-morrow.远远地，远远隐没，让我忘掉你在林间从不知道的一切忘记这疲劳、热病和焦躁这使人对坐而悲叹的世界在这里，青春，苍白，削瘦，死亡而瘫痪有几根白发在摇摆在这里，稍一思索就充满了忧伤和灰暗的绝望而美保持不住明眸的光彩新生的爱情活不到明天就枯凋 chapter forthAway! away! for I will fly to thee,Not charioted by Bacchus and his pards,But on the viewless wings of Poesy,Though the dull brain perplexes and retards.Already with thee! tender is the night,And haply the Queen-Moon is on her throne,Clustered around by all her starry Fays;But here there is no light,Save what from heaven is with the breezes blownThrough verduous glooms and winding mossy ways.去吧！去吧！我要朝你飞去，不用和酒神坐文豹的车架，我要展开诗歌底无形的羽翼，尽管这头脑已经困顿，疲乏。去了，我已经和你同住；夜这般温柔，月后正登上宝座周围是侍卫她的一群星星，但这儿不甚明亮，除了有一线天光，被微风带过，葱绿的幽暗和藓苔的曲径。 chapter fiveI cannot see what flowers are at my feet,Nor what soft incense hangs upon the boughs ,But, in embalmed darkness, guess each sweetWhere with the seasonable month endowsThe grass, the thicket, and the fruit-tree wild –White hawthorn, and the pastoral eglantine;Fast fading violets covered up in leaves;And mid-May’s eldest child,The coming musk-rose, full of dewy wine,The murmurous haunt of flies on summer eves.我看不出是哪种在脚旁什么清香的花挂在树枝上在温馨的幽暗里，我只能猜想这时令该把哪种芬芳赋予这果树，林莽和草丛这白枳花，和田野的玫瑰这绿叶堆中易凋谢的紫罗兰还有五月中旬的娇宠这缀满了露酒的麝香蔷薇它成了夏夜蚊蚋嗡营店港湾 chapter sixDarkling I listen; and for many a timeI have been half in love with easeful Death,Called him soft names in many a mused rhyme ,To take into the air my quiet breath;Now more than ever seems it rich to die,To cease upon the midnight with no pain,While thou art pouring forth thy soul abroadIn such an ecstasy!Still wouldst thou sing, and I have ears in vain –To thy high requiem become a sod.我在黑暗里倾听，多少次我几乎爱上了静谧的死亡我在诗思里用尽了我言辞求他把我的一息散入空茫而现在，死更是多么的富丽在午夜里溘然魂离人间当你正倾泻你的心怀发出这般的狂喜你仍将歌唱，但我却不再听你的莽歌只能唱给泥草的一块 chapter sevenThou wast not born for death, immortal Bird !No hungry generations tread thee down;The voice I hear this passing night eas heardIn ancient days by emperor and clown :Perhaps the self-same song that found a pathThrough the sad heart of Ruth, when, sick for home,She stood in tears amid the alien corn;The same that oft-times hathCharmed magic casements, opening on the foamOf perilous seas, in faery lands forlorn.永生的鸟，你不会死去饿的世代无法将你蹂躏今夜，我偶然听到的歌曲当使古代的帝王和村夫喜悦或许这同样的歌也曾激荡露丝忧郁的心，使她不禁落泪站在异邦的谷田里想着家就是这声音常常在失掉了的仙域里引动窗扉一个美女望着大海险恶的浪花 chapter eightForlorn! the very word is like a bellTo toll me back from thee to my sole self!Adieu! the fancy cannot cheat so wellAs she is famed to do, deceiving elf.Adieu! adieu! thy plaintive anthem fadesPast the near meadows, over the still stream,Up the hill-side; and now ‘tis buried deepIn the next valley-glades:Was is a vision, or a waking dream?Fled is that music – Do I wake or sleep?失掉了，这句话好比一声钟使我猛省到我站脚的地方别了！幻想，这骗人的妖童不能老耍弄它盛传的伎俩别了！别了！你怨诉的歌声流过草坪，越过幽静的溪水溜上山坡，而此时它正深深埋在附近的溪谷中这是个幻觉，还是梦寐那歌声去了-我是睡？是醒？ 穆旦先生的原名是查良铮，说起这个名字或许大家并不熟悉，却不由的联想起查良镛这个名字来，而这个名字正是金庸先生的原名。通过调查，穆旦先生与金庸先生为同族兄弟。 Sonnets From The Portuguese 篇幅比较长，闻一多先生的译本没有找到，不过方平先生的译本也很好。 所有的篇幅不再一一展示，这里就摘抄了印象深刻的几句： Behind me, and drew me backward by the hair; And a voice said in mastery, while I strove, – Guess now who holds thee? – Death. I said. But, there The silver answer rang, – Not Death, but love. Our hands would touch for all the mountain-bars And, heaven being rolled between us at the end, We should but vow the faster for the stars. Thou hast thy calling to some palace-floor, Most gracious singer of the high poems! where The dancers will break footing, from the care Of watching up thy pregnant lips for more. And dost thou lift this house’s latch too poor For hand of thine? and canst thou think and bear To let thy music drop here unaware In folds of golden fulness at my door? 2017年的反思（Self-examination） 生活（About Life） 作息不好，睡的很晚，有一段时间居然每天晚上都到了凌晨三四点才爬上了床。 没有充分利用自己的时间，被二次元的事情占据了很多的时间，却并没有那么多的时间去看书，去做自己的事情了。 和父母的打电话的时间变得越来越少，很少去图书馆，每天看电脑的时间变得很长，社交的生活过于丰富了。 习惯（About Habits） 失去的好习惯 坚持了一年的每天晚上看一个小时的日语的习惯 笔书的习惯（感觉字越来越难看） 坚持了两年的做读书笔记的习惯 2018年的规划（Planning） 学业（About Work） 实践 希望可以在实习的阶段更好的锻炼自己，找到一份很好的实习机会。 希望国家级项目可以顺利完结。 课设 认真的对待自己每一次的project，要从性能，从实用上继续进步。 基础 数学基础很重要，离散、代数、密码学不能忘记，希望可以夯实基础。 数据结构、操作系统、计算机组成原理都是基础，希望可以再总结一次，做一次长期的打算，每周复习一点。 外语 希望可以再续之前的语言习惯，英语和日语可以每晚练习。 爱好（About Hobbies） 社团 会少花一些精力，但是仍然会做自己喜欢的剧，继续出高质量的作品。 看书 希望每个月都可以写一篇读书笔记，每个月都有一本自己最喜欢的书。 合唱 每周日晚上7:00到9:00的排练。 生活（About Life） 作息 早睡早起，不能让父母亲担心身体的问题，也应该对自己负责。母亲说的很对，五点起床比凌晨睡觉更好。 运动 每周两次羽毛球。 时间规划 效率最重要，效率最重要，效率最重要。重要的事情说三遍！！！ 写给自己（To myself） 总结（summary） 时间是最大的财富，让时间变得更有价值 网易云的歌单年度的总结，属于我的词恰好是“时间“。 到了20岁，开始感觉到了紧迫感，开始有一点时不我待的感觉。时光匆匆，希望可以在最好的时光里做一些不负青春的事情。 家人很重要，爱自己，爱生活 这次回家，身体状况让父母有一点担心，虽然我开玩笑的说自己17年连感冒都没有得过。但是经常的熬夜让父母担忧了，虽然计算机专业，做一些课设项目会通宵，但是希望自己不要把熬夜视为理所当然。 爱生活，去记录自己的生活，去展示自己的生活。 开销要节制一点 大三上，花钱有一点大手大脚的。还是恢复一起记账的习惯，对自己的开销要有认识，不花不应该花的钱了。","categories":[{"name":"notes","slug":"notes","permalink":"http://AndyQianq.github.io/categories/notes/"}],"tags":[{"name":"diary","slug":"diary","permalink":"http://AndyQianq.github.io/tags/diary/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-02-03T15:06:57.055Z","updated":"2018-02-27T13:34:51.366Z","comments":true,"path":"2018/02/03/hello-world/","link":"","permalink":"http://AndyQianq.github.io/2018/02/03/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://AndyQianq.github.io/tags/hexo/"}]},{"title":"这就是生活","slug":"这就是生活","date":"2017-12-14T18:07:35.000Z","updated":"2018-02-25T17:50:54.615Z","comments":true,"path":"2017/12/15/这就是生活/","link":"","permalink":"http://AndyQianq.github.io/2017/12/15/这就是生活/","excerpt":"","text":"“好久不见”“嗯……”“最近过的还好吗？”“还好……” 段段续续的聊天记录，明明加起来还没有二十个字的对话，整整花了1个小时。 看着对话框里的光标不停闪现，你心里那么的不甘，明明有那么多话想对她说，删了又打，打到一半又忍不住删掉，结果折腾了这么久，还是用那么老套的开头。 不知不觉，一年过去了，你发现自己还是那么别扭而又自卑。 “今天是你生日吗？生日快乐。” 突然看到她发来的这一句，你拿着手机，不在意的理了理头发，装作一副不在意的样子，就好像她在你的身边能看见你一样，而你又有点固执地不想让她看见你略带欣喜的表情。 “嗯” 过了几分钟，她没有回你，你开始着急了，你埋怨自己不应该那么敷衍地只说一声“嗯”，最起码应该再加一句“谢谢”。 你忽然想起一年前，你千方百计的要来她的电话。拨号盘里，你一个数字一个数字的输进去，想着打给她的那天，听着她在电话那边温柔的声音，想着或许以后你就会通过这个号码告诉她你喜欢她。 然而，等你鼓起勇气打给她的时候，只剩下那边的沉默，和你尴尬的独白。 她的声音还是那么温柔，然后礼貌地拒绝了你的邀请，她说“我现在有一点忙，最近有一个报告要写，等有时间了再说好吗？” 你有点自嘲，到底是什么让你觉得自己在她面前总能败下阵来，又到底是什么让你那么害怕她的沉默。在她的面前你觉得自己像个永远不被看好的学生，那么希望在她哪里拿到满分。当你所做的一切都是为了讨好那么一个人，你是那么希望得到回应，结果那个人偏偏看不见，或者说她不愿意看见。 因为或许对于她来说不喜欢就是零分，就算她明明能听出来电话那边的那个忐忑不安的你是那么的努力讨好她，明明能感觉到现在手机这边的那个小心翼翼的你是那么的纠结，可是“不爱”两个字在那个你原本费劲心血编写的剧本里，给所有的一切打上了一个句号。 从此，这段失败的感情没有给你留下半分的美好。曾经因为那个人留下的零零散散的记忆拼凑成一个一个玻璃渣，一开始揉在你的心里，你疼的撕心裂肺，慢慢的，就嵌进伤口里了，变成了你的后遗症。 一年里，你尝试开始一段新的感情，你假装不在意地对周围的人说“不就是女朋友吗，哥明天就能找打一个更好的”，然后笑的没心没肺。结果他们真的都忘了一年前那个因为失恋而喝个烂醉的你，只剩下你把那个晚上痛彻心扉的感觉刻在了记忆深处。 不知不觉，你盯着那个光标又看了一个小时，你瞅了瞅时间，12点过了，已经不再是你的生日了，其实是不是你的生日都不重要。 你酸酸的打出“晚安”发了过去，想到早上起来她又会在你的列表里沉默，你在心里骂了一句“傻逼”，然后爬上了床。","categories":[{"name":"notes","slug":"notes","permalink":"http://AndyQianq.github.io/categories/notes/"}],"tags":[{"name":"novel","slug":"novel","permalink":"http://AndyQianq.github.io/tags/novel/"}]},{"title":"配乐推荐","slug":"配乐介绍","date":"2017-10-28T04:16:46.000Z","updated":"2018-02-27T13:31:57.614Z","comments":true,"path":"2017/10/28/配乐介绍/","link":"","permalink":"http://AndyQianq.github.io/2017/10/28/配乐介绍/","excerpt":"","text":"写在前面 1.排名不分先后。 2.我听的不多，所以还有没有写入的优秀的配乐者，是我还没有遇到。 3.会不定期更新名单。 4.作为广播剧后期，这里仅供后期参考，无评论含义。 国内配乐推荐 配乐之古风篇 经典 赵季平、麦振鸿、程池 新声力 阿鲲、魏小涵、孟可 游戏配乐 小旭音乐 布袋戏 霹雳英雄 详细介绍 赵季平 介绍赵季平出生于甘肃平凉，长期生活在陕西，家就在西安碑林博物馆旁。赵季平从小就酷爱音乐，在音乐学院时，他苦苦钻研，加上他颇具灵气，已小有名气。此后，他几乎涉及了音乐创作的各个领域：小合唱、表演唱、民族管弦乐、交响音乐、歌剧、舞剧、戏曲音乐等等。他成为电影作曲家后，在创作风格上历经了三个阶段：一是在《黄土地》中，音乐与影片风格一致；二是《红高粱》时，音乐已完全融入电影，加强了影片的艺术感染力；三是到《大红灯笼高高挂》时，音乐在思想性和艺术性方面超出了影片，达到一种新的境界。主要作品自1984年为电影《黄土地》作曲以来，先后为四十多部影片作曲，其中为《大阅兵》、《红高粱》、《菊豆》、《五个女子和一根绳子》、《大红灯笼高高挂》、《烈火金钢（上下）》、《心香》、《秋菊打官司》、《霸王别姬》、《活着》、《炮打双灯》、《步入辉煌》、《黄沙·青草·红太阳》、《变脸》、《风月》、《日光峡谷》、《秦颂》、《孔繁森》等影片所作音乐多次在国内和国际电影节上获奖。推荐曲目推荐原因 麦振鸿 代表作《仙剑》系列，《聊斋》系列推荐曲目推荐原因 阿鲲 代表作《舌尖》系列，《华胥引》配乐推荐曲目推荐原因 孟可 代表作《琅琊榜》配乐推荐作品 小旭音乐 代表作 魏小涵 代表作《天谕》系列推荐作品 霹雳英雄 代表作 配乐之民国篇 陈其钢 代表作《我和你》、《金陵十三钗》配乐推荐曲目 配乐之校园青春篇 郭思达 代表作","categories":[{"name":"music","slug":"music","permalink":"http://AndyQianq.github.io/categories/music/"}],"tags":[{"name":"配乐推荐","slug":"配乐推荐","permalink":"http://AndyQianq.github.io/tags/配乐推荐/"}]},{"title":"自然语言处理(natural language processing)","slug":"natural-language-processing","date":"2017-09-28T15:05:09.000Z","updated":"2018-03-07T18:12:50.542Z","comments":true,"path":"2017/09/28/natural-language-processing/","link":"","permalink":"http://AndyQianq.github.io/2017/09/28/natural-language-processing/","excerpt":"","text":"自然语言处理n-gram算法阅读前建议 读者可以阅读《数学之美》（吴军著），里面的内容浅显易懂，适合对计算机领域有兴趣的人群阅读。 正文部分 Natural Language Processing是AI的一个子领域，在NLP（自然语言处理）中有一个很有意思的问题： 此处引用百度百科的例子： “我们把香蕉给猴子，因为它们饿了” “我们把香蕉给猴子，因为它们熟透了” 你一定可以很快的看出“它们”在这两个句子里分别指的是猴子和香蕉。那么问题来了，机器是如何识别“它们”在不同句子里的指代呢？ 这也是自然语言处理中常见的问题，即语义的理解。 除此之外，自然语言中还存在很多存在歧义的词语，同音的词语，句法也存在模糊性。随着网络不断深入人们的生活，网络用词，例如近年来的“呵呵”“给力”等词语，都增加了问题的难度，甚至还出现了一些根本不存在的词语。在这些问题的上，很多前辈都做出了不少的努力。（如果想要了解这段历史可以阅读《数学之美》系列八贾里尼克的故事和现代语言处理和系列二十一自然语言处理的教父-马库斯） 统计语言模型 成功利用数学方法解决自然语言处理问题的是贾里尼克，就是他提出了统计语言模型。 那么什么是统计语言模型？ 如果用S表示一段特定序列的词语w1，w2……wn组成的句子，那么机器对语言的识别从一定角度来看就是知道S在文本中出现的可能性。 即P（S）=P（w1）P（w2|w1）P（w3|w1w2）……P（wn|w1w2……wn-1） 通过马尔科夫假设，我们假定任意一个词wi的出现该来只和它前面的wi-1有关，那么S出现的概率为： P（S）=P（w1）P（w2|w1）P（w3|w2）……P（wi|wi-1）…… （这里的wi-1可以取wi-n即一个词可以由前面的N-1个词来决定） 注释： 马尔科夫假设： t+1时刻系统状态的概率分布只和t时刻的状态有关，与t时刻以前的状态无关； 从t时刻到t+1时刻的状态转移和t的值无关。（有兴趣深入了解可以阅读《信息论与编码》电子科技大学出版第二章第七节：马尔可夫信源） 那么在得到一个足够完善的词料库之后，我们通过统计词频，就可以通过计算得到一个句子的出现的概率，自然概率越高，这个句子就符合该语料下的规则。 这里又提出了一个概念即n-gram语言模型 由刚刚的统计语言模型，我们不妨假设wi的概率由w1，……wi-1来决定，那么设这个特定的一组序列w，……，wi-1成为wi的历史（history） 显然我们意识到一个问题：随着历史基元的增长，不同的历史（路径）会按照指数级增长。对于第i个统计基元，历史基元的个数为i-1，如果共有L个不同的基元，则i基元就有Li-1种不同的历史情况。模型中有Lm个自由参数P（wm|w1……wm-1）. 那么这里举个例子，当L=5000，m=3，自由参数的数目为1250亿。自然这时我们必须想一个解决的方法，这里最直接的想法就是减少历史基元的个数即使用等价类，利用一个映射，将w1w2……wi-1映射到 S（w1w2……wi-1）。自然等价类的数目是远远小于原来不同历史基元的数目的。 P（wi|w1……wi-1）=P（wi| S（w1w2……wi-1）） 有了这个想法，我们自然就要考虑如果划分等价类。基于这种想法，我们提出了n元文法 n=1——》uni-gram 即wi独立于历史 n=2——》bi-gram 基于1阶马尔可夫链 n=3——》tri-gram 基于2阶马尔可夫链 再举一个简单的例子： 给定句子：John read a book 增加标记：(BOS)John read a book(EOS) Unigram：(BOS), John, read, a, book, (EOS) Bigram: ((BOS)John), (John read), (read a), (a book), (book (EOS)) Trigram: ((BOS)John read), (John read a), (read a book), (a book (EOS)) 即二元文法的概率为： P(John read a book) =P(John(BOS)×P(read|John)×P(a|read)×P(book|a)×P((EOS)|book) 补充 如果汉字的总数为：N 一元语法： 1）样本空间为 N 2）只选择使用频率最高的汉字 二元语法： 1）样本空间为 N2 2）效果比一元语法明显提高 估计对汉字而言四元语法效果会好一些 智能狂拼、微软拼音输入法基于 n-gram. 那么问题又来了，如何得到n-gram文法？ 这里引入两个概念： Training data（训练语料）：用于建立模型，确定模型参数的已知语料 Maximum Likelihood Evaluation（最大似然估计）：用相对频率计算概率的方法例子 例如，这里给定训练语料： “John read Moby Dick”， “Mary read a different book”, “She read a book by Cher” 那么2元文法求句子的概率为多少？（读者最好自己思考一下） 解答 首先我们对句子进行标识 (BOS)John read Moby Dick(EOS) (BOS)Mary read a different book(EOS) (BOS)She read a book by Cher(EOS) 通过上面所说的二元文法概念我们很容易得到John read a book的概率为： 但是如果我们要处理的句子是：Cher read a book呢？ 很快我们发现，语料中并没有cher这个单词，那么自然这个句子的概率就是0了。 这其实是NLP中常见的问题，即数据匮乏而引起的零概率问题，如何解决这个问题，即我们要说明的第二个重点。 data smoothing（数据平滑处理）引入 数据平滑的基本思想可以用一个词语概括：“劫富济贫” 即使得零概率增值，使得非零概率下调。 但是这个思想要基于一个基本约束，即： 方法分类 这里我们介绍一下几种常见的数据平滑处理方法： 1） 拉普拉斯平滑（加1法） 2） 古德图灵法（good-turing） 3） Katz后退法（Back-off） 4） 绝对值减法（Absolute Discounting） 5） 线性减值法（Linear Discounting） 这里重点讲一下（1）和（2） 加一法：拉普拉斯平滑 对于2-gram： 其中，V 为被考虑语料的词汇量（全部可能的基元数）。 例子 (BOS)John read Moby Dick(EOS) (BOS)Mary read a different book(EOS) (BOS)She read a book by Cher(EOS) P(Cher read a book) = P(Cher|(BOS)×P(read|Cher)×P(a|read)×P(book|a)× P((EOS)|book) 没有处理： P(Cher|(BOS)) = 0/3 P(read|Cher) = 0/1 P(a|read) = 2/3 P(book|a) = 1/2 P((EOS)|book)= 1/2 词汇量：|V|＝11 平滑以后： P(Cher|(BOS)) = (0+1)/(11+3) = 1/14 P(read|Cher) = (0+1)/(11+1) = 1/12 P(a|read) = (1+2)/(11+3) = 3/14 P(book|a) = (1+1)/(11+2) = 2/13 P((EOS)|book)= (1+1)/(11+2) = 2/13 P(Cher read a book) = 0.00003 同理: P(John|(BOS)) = 2/14, P(read|John) = 2/12, P(a|read) = 3/14, P(book|a) = 2/13, P(John read a book)=P(John|(BOS))×P(read|John)×P(a|read)×P(book|a)×P((EOS)|book)=0.0001 减值法： 基本思想：修改训练样本中事件的实际计数，使样本中(实际出现的)不同事件的概率之和小于1，剩余的概率量分配给未见概率。 以上所说的2）3）4）5）均属于减值法 这里重点说一下2）Good-Turing估计 这种估计适用于大词汇集产生的符合多项式分布的大量的观察数据。 Good-Turing估计 内容： 假设 N 是原来训练样本数据的大小， nr 是在样本中正好出现 r 次的事件的数目(在这里，事件为 n-gram w1, w2, …, wn)，即：出现 1 次的 n1个，出现 2 次的 n2个, …… 例子 这里也举一个例子，引用 总结 其余几种减值法的数据平滑读者可以查询其余资料，这里就不累述了。这里我只是简单的对这四种减值法比较，读者可以通过比较进行针对的查询。 Good-Turing 法：对非0事件按公式削减出现的次 数，余留出来的概率均分给0概率事件。 Katz 后退法：对非0事件按Good-Turing法计算减 值，余留出来的概率按低阶分布分给0概率事件。 绝对减值法：对非0事件无条件削减某一固定的出现次数值，余留出来的概率均分给0概率事件。 线性减值法：对非0事件根据出现次数按比例削减次数值，余留出来的概率均分给0概率事件。 3月7日晚补充 前几天把之前自然语言课上的代码git上去了，这里补充一下连接 是一个基于java的“宋词生成系统”和“中文分词系统”，有兴趣的可以观看一下 宋词生成系统和中文分词系统","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"learning","slug":"learning","permalink":"http://AndyQianq.github.io/tags/learning/"},{"name":"nlp","slug":"nlp","permalink":"http://AndyQianq.github.io/tags/nlp/"}]},{"title":"鲸落","slug":"鲸落","date":"2017-07-23T02:18:51.000Z","updated":"2018-03-01T15:39:35.316Z","comments":true,"path":"2017/07/23/鲸落/","link":"","permalink":"http://AndyQianq.github.io/2017/07/23/鲸落/","excerpt":"","text":"写在前面 最近给社团画的练习图，记录了绘画过程。 自学板绘也学了半年了，之前撸了那么多次sai，现在终于进阶到了ps了。 花了一下午，从昨天晚上收集资料，花了6、7个小时的时间。 此教程适合小白使用。 正文部分关于鲸落主题 “你知道这世界上有 一种现象叫‘鲸落’吗？鲸鱼死后尸体沉 在海底下，供养其他水生物仍能生活几 十年，在我看来就像一个温柔的奇迹， 用自己的身体，建立起一个孤独的岛屿。”——《深海中的温柔孤岛》 全世界鲸目物种有80多个，但是只有达到30吨级别的大型鲸才能真正形成繁盛的鲸落——这就只剩下不到十种，而其中一半是濒危的。过去两百年里，工业化捕鲸将大型鲸推入了十分危急的境地，今天全球海洋里的鲸落数量，可能只有以前的不足六分之一。 准备工作新建文件 我是选择A4纸格式、分辨率定为300 这里说一下，如果要考虑图片的打印效果，分辨率默认是300，但是如果是平时作图，不用打印的话，72的分辨率就绰绰有余了 关于构图 既然是鲸落，首先想到的就是鲸鱼啊! 在资料的部分我讲过，座头鲸比较适合作画。 原因如下： 1.体型大但是结构匀称，不想抹香鲸显得头重脚轻。 2.色彩统一，不像虎鲸的颜色对比太过于显眼。 3.座头鲸又叫做“大翅鲸”，鱼鳍宽大，很容易让画面显得飘逸。 如果画面只有一条鲸鱼，一来画面单调，二来没有参考物，读者感受不到鲸鱼的庞大. 就像学《逍遥游》的时候 北冥有鱼，其名为鲲,鲲之大不知其几千里也。 文字可以用几千里来做比较，但是画面只有A4纸的大小。 于是，我加了一个少女的形象来作为参照。 建议画图的时候，打开导航器，就可以直观的感受画面效果。主要工作环境色 粗略的完成线稿之后，开始铺色，对画面进行定调,可以使用大面积的喷枪上色 PS:但是对于ps来说，当笔的像素跳到1000以上之后，会有很可怕的延迟然后电脑开始嗡嗡作响，有些老式机会直接停机，尤其是联想的。。。真的，再好的pc机都会出现这种现象，不要问我怎么知道的 这里稍微提一下：在笔刷这一部分真的还是专业的绘图软件比较好，毕竟ps只是图像处理工具 推荐的绘图工具有： sai painter 但是以上的软件也有自己的缺点 例如sai在厚涂方面表现一般，笔触过于平滑，很难处理细节，色彩上也过于小清新，表现的风格会收到局限。 painter则是专业的绘图软件，但是占用的内存较大，颜色丰富，笔触细腻，问题是对于刚刚入门的萌新们，看到那么多的功能会很懵逼的好嘛（躲在墙角瑟瑟发抖）。 另一方面，painter在大陆的受众比较少，在网上找资源教程什么的比较难，台湾等部分地区使用比较广泛。 如果不用大笔刷铺色的话，其实ps里还是用其他很好用的工具可以代替的 这里我使用了工具栏处的“渐变”处理,对角线一拉，马上自然过渡 然后在用笔刷增加一点笔触进去 光效果 例如加入一下水波的痕迹，然后开始加入发光的效果（效果如下） 为什么这么早加入发光特效 因为这样对于后面展现主题的细节有好处啊 有了光之后，你就能知道在鲸鱼的什么地方是暗面，什么地方是亮面了啊。。。这样该有高光的地方你就加去嘛 对于小白，这一招还是蛮好用的 好了，说一下发光特效怎么加 首先选一张深海的光源图 例如 然后选择你想要的光源部分 control+c control+v 复制得到的图层命名为“光源” 放在线稿的下面，铺色的上面 然后在图层效果里选择——颜色加深 细节上色 首先完善一下鲸鱼的感觉，塑造一下明暗面： 这里新建一个图层，用模糊笔刷浓度调节到40～50%之间，给鲸鱼的脊背上色。 高光的部分用30号笔刷上色。 通过光线来判断亮面和高光的位置。 现在我们再处理一下人物，虽然这幅图的人物不是重点。 我们来看一下这个略low的小人。 现在我们给小人上一些颜色。 注意上色的时候不能用过于鲜艳的颜色，不然会显得画面很突兀。 现在我们看看这幅图的整体效果： 审视一下有没有什么问题，然后重头戏就来了——为画面加入细节。 一幅画一眼看上去颜色不能辣眼睛，这是刚刚一些列做的事 而一幅画到底耐不耐，这里继续在画面的主体（鲸鱼）上加入细节，这里就可以好好利用鲸落的主题了，就是那种虽死犹生的衰败的美感嘛（原谅我糟糠的语言表达。。。） 加入细节的地方要用更细腻的笔触，这里选用的是25号笔刷加入纹路。 一点一点的擦去线稿里粗糙的线条,用30号笔刷制造伤痕。 我们在来看一下效果： 其实细节还可以再加很多，例如后期看可以为了让害民啊看起啦更真实，在加入气泡，血丝，小鱼之类的,这里由于时间的关系就不多说了。 如果只是单纯的一幅图的画，（好吧作为一个完成度不是特别高的图，例如小人那个地方我就比较偷懒。。。）也就差不多了。 关于字体 首先在素材包里打开字体图片 然后在右下角处面板点开通道页 点击右下角的将通道作为选区载入 再点击菜单栏的选择——》反选 接下来就是复制、粘贴了 粘贴到新建的文件后会在原先的背景上新增图层，也就是我们刚刚复制的文字图层。 但是文字太小了，所以这里进行放大文字。 点击菜单栏——》编辑——》变化——》缩放 最后成品 总结 这是第一次用ps撸图，不足之处还望见谅。 时间仓促，有些细节可能有错误，大部分地方大家可以随个人喜好自己添加。 2017年7月初稿，于2018年2月修订一次，但是发表时间还是写在了2017年7月23日。 大二时候写的东西了，不够简洁，语言啰嗦，感谢您观看到最后！","categories":[{"name":"hobbies","slug":"hobbies","permalink":"http://AndyQianq.github.io/categories/hobbies/"}],"tags":[{"name":"painting","slug":"painting","permalink":"http://AndyQianq.github.io/tags/painting/"}]},{"title":"legendre&Jacobi","slug":"legendre-Jacobi","date":"2017-04-13T08:30:44.000Z","updated":"2018-03-01T15:46:56.176Z","comments":true,"path":"2017/04/13/legendre-Jacobi/","link":"","permalink":"http://AndyQianq.github.io/2017/04/13/legendre-Jacobi/","excerpt":"","text":"参考用书《密码学原理与实践》第三版（Douglas R. Stinson 著，冯登国等译） 数论基础 说到这两个符号，不得不把数论上的一些知识回顾一下~ 数论中常见的运算就是模运算。 模，我们在高中的时候就见过这个符号mod 那么在数论中出现的同余式运算例如 同余式 二次同余式 可以使用欧拉判别法 Euler判别法 legendre符号的简单描述 勒让德(Legendre , A. -M.)于1798年发表的专著《关于数论的研究》中，系统地整理了数论研究的成果。 其中legedre符号描述如下： 由此得到了很多的推论 推论１ 推论2 推论3 Jacobi符号的介绍 注意上述legendre符号只能适用于p为奇素数 那么对于一般的正整数m 要判断方程x^{2}\\equiv a(mod m)是否有解 见图：（懒得打字了） 所以说白了，Jacobi就是Legendre的一种特殊情况，legendre是Jacobi的一种推广。 所以要编写Jacobi符号的程序，可以借用Legendre符号，在已有的基础上将m进行分解。 首先输入m（分母）后，我们首先判断m是否是奇素数，如果是直接用legendre符号计算，如果不是那么就对m进行分解，直到分解后的结果满足是奇素数为止。 但是如何对jacobi符号进行有效的分解？ 从表面上看，好像要先对n进行因子分解，因为jacobi符号\\left( \\frac{a}{n} \\right) 的定义就是n 的因子分解组成的项。但是，如果我们已经知道了n的因子分解，就知道了n是否为素数；所以，这种方式就陷入了错误的循环。 但是，我们可以利用一些数论上的结果，无须分解n就可以求出jacobi符号的值，其中最重要的一条就是二次互反律的一般形式（见下面的性质4）。 此处有一个例题可供参考 测试代码点此处","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"cryptology","slug":"cryptology","permalink":"http://AndyQianq.github.io/tags/cryptology/"},{"name":"learning","slug":"learning","permalink":"http://AndyQianq.github.io/tags/learning/"}]},{"title":"AES加密","slug":"AES加密","date":"2017-03-21T12:12:13.000Z","updated":"2018-02-23T12:55:19.075Z","comments":true,"path":"2017/03/21/AES加密/","link":"","permalink":"http://AndyQianq.github.io/2017/03/21/AES加密/","excerpt":"","text":"高级加密标准 1997年9月12日NIST（National Institute of Standards and Technology）发布了征集算法公告，要求AES具有128比特的分组长度，并支持128，192和256比特长度的密钥长度，并且要求AES可在全世界范围内免费得到。 1998年6月15日，在提交的21个算法里，有15个满足所有必备的条件并被接纳为AES的候选算法。1999年三月，NIST举行了“第二届AES候选大会”，之后，在1999年8月，5个候选算法入围最后决赛：MARS、RC6、Rijndael、Serpent和Twofish。 2000年10月2日，Rijndael被评为高级加密标准。 说了这么多就是告诉你Rijndael被评为AES是经过层层选拔而来的，是实至名归。那么它究竟怎么实现，才是这篇文章的重点 从上面的文字我们要知道以下几点： 1.AES具有128比特的分组长度2.AES有三种可选的密钥长度3.AES是一个迭代型密码 好了我们在分别说一下 1.什么是分组长度？2.三种可选择的密钥长度有什么不同？3.什么是迭代密码？ 1.分组长度 说到分组长度，自然要讲分组密码 2.不同在于 密钥为128比特，则Nr=10密钥为192比特，则Nr=12密钥为256比特，则Nr=14 3.迭代密码 常见的乘积密码是迭代密码 一个典型的迭代密码：这种密码要明确定义一个轮函数和一个密钥编排方案，一个明文的加密将经过Nr轮类似的过程。 注： 乘积密码（通过“乘积”组合密码体制）“乘积”要满足：具有相同的明文空间（密文空间） 说了这么多，大家懂的也不用听我瞎BB（反正这些也是教材上说的），不懂的听我说也是不懂。。。 下面我们切入正题： 首先我们看一下最简单的密钥为128比特的流程图： 注释：Add round key:密钥加Substitute bytes:字节代换Mix columns:列混淆Shift rows:行移位（只看左边，右边是逆过程。） 从图中我们可以看出在10轮中 第一步：明文与密钥加第二步：密钥扩展第三步：进入第一轮…….最后：进入第十轮 那么每一轮都有什么呢？ 首先我们要注意：前面的几轮与最后一轮是不同的前几轮：1.密钥加，2.字节代换，3.行移位，4.列混淆最后一轮：1.密钥加，2.字节代换，3.行移位所以可以看出列混淆比其他的操作要少一轮！ 密钥加应该都会吧。。。 例如明文为：密钥为：就是每个格子里的数对应\\oplus举个例子就是32\\oplus 2b因为是16进制数，也就是32：001100102b：0010101100011001=19 好接下来我们在解决每一轮的是如何完成这些操作的： 1.密钥扩展 这里输入128比特的密钥是一位数组，每个元素是16进制，也就是8个比特，共16个元素，要扩展成44个。 &gt; 2.字节代换 字节代换会引入一个S盒的概念，会有人问S盒在不同的算法里是否一致，答案当然是不一样咯。S盒的概念在SPN（代换-置换网络）中有详细的解释，就不多说了。（想知道的，在下一篇文章中再说吧）这里为了方便，姑且认为这个S盒是统一的吧。 你可以选择在算法里一个个的输入到二维数组中存储，但是。。。。我比较偷懒，所以在找了一个可以计算S盒的算法出自于论文：《AES加密算法中的S盒及其C语言实现》 出处：AES加密算法中的S盒及其C语言实现 有了S盒之后，那么只需要将每次密钥加的结果字节代换到S盒中 举个例子就是 以19为例，就是S盒中第1行第9列中的十六进制数为：d4最后的结果就是 3.行移位 行移位很简单： 第一行不变第二行每位向左移一位第三行每位向左移两位第四行每位向左移三位 4.列混淆 列混淆会复杂一点： 大家应该学过线性代数吧，所以这个就是一个行列式的计算，但是这里还有一个多项式的域运算问题： Xtime就是：D4：11000100因为d4的二进制开头是1所以：从第二位开始向左进一位在最后一位补充0于是：10001000再和“1B”\\oplus也就是：1000100000011011结果为：10010011=93（如果开头是0，那么就直接从第二位开始向左移一位，在最后一位补0即可）D4·02=xtime（d4）=93D4·03=d4\\oplus xtime（d4）=57110001001001001101010111=57D4·01=d4那么d4对应的列混淆就是D4·02\\oplus d4·03\\oplus d4·01\\oplus d4·01=04所以最后的结果就是： 好了解决了各个部分之后，我们在来分别实现代码 C语言 1.密钥扩展123456789101112131415161718192021222324252627void KeyExpansion(int sbx_tab[][16],int keys[][44])&#123; int Rcon[11]=&#123;0,1,2,4,8,16,32,64,128,27,54&#125;; int past[4]; int i,j; printf(&quot;input the keys:\\n&quot;); for(i=0;i&lt;4;i++) for(j=0;j&lt;4;j++) scanf(&quot;%x&quot;,&amp;keys[j][i]); for(i=4;i&lt;44;i++) &#123; if(i%4==0)&#123; for(j=1;j&lt;=4;j++) past[j-1]=keys[j%4][i-1]; for(j=0;j&lt;4;j++)&#123; if(j==0) keys[j][i]=sbx_tab[past[j]/16][past[j]%16]^Rcon[i/4]^keys[j][i-4]; else keys[j][i]=sbx_tab[past[j]/16][past[j]%16]^keys[j][i-4]; &#125; &#125; else&#123; for(j=0;j&lt;4;j++)&#123; keys[j][i]=keys[j][i-4]^keys[j][i-1]; &#125; &#125; &#125;&#125; 2.字节代换123456789101112131415//SubByte字节替换void SubByte(int sbx_tab[][16],int B[][4])&#123; int i,j; for(i=0;i&lt;4;i++) for(j=0;j&lt;4;j++)&#123; B[i][j]=B[i][j]%256; B[i][j]=sbx_tab[B[i][j]/16][B[i][j]%16]; &#125; for(i=0;i&lt;4;i++)&#123; for(j=0;j&lt;4;j++) printf(&quot;%X &quot;,B[i][j]); printf(&quot;\\n&quot;); &#125;&#125; 3.行移位1234567891011121314151617181920//ShitfRow行移位void ShiftRow(int B[][4])&#123; int m=1; int i,j; while(m&lt;4)&#123; for(i=m;i&lt;4;i++) &#123; int tem = B[i][0]; for (j=0;j&lt;3;j++) B[i][j] = B[i][j+1]; B[i][3] = tem; &#125; m++; &#125; for(i=0;i&lt;4;i++)&#123; for(j=0;j&lt;4;j++) printf(&quot;%x &quot;,B[i][j]); printf(&quot;\\n&quot;); &#125;&#125; 4.列混淆1234567891011121314151617181920212223242526int Xtime(int input)&#123; int temp; temp=input&lt;&lt;1; if(input&amp;0x80) &#123; temp^=0x1b; &#125; return temp;&#125;//MixColumn列混淆void MixColumn(int input[][4])&#123; int i,j; int output[4][4]; for(j=0;j&lt;4;j++) for(i=0;i&lt;4;i++)//0x02乘法//0x03乘法//0x01乘法//0x01乘法 output[i][j]=Xtime(input[i%4][j])^(input[(i+1)%4][j]^Xtime(input[(i+1)%4][j]))^input[(i+2)%4][j]^input[(i+3)%4][j]; for(i=0;i&lt;4;i++) for(j=0;j&lt;4;j++) input[i][j]=output[i][j]; for(i=0;i&lt;4;i++)&#123; for(j=0;j&lt;4;j++) printf(&quot;%02X &quot;,output[i][j]); printf(&quot;\\n&quot;); &#125;&#125; 5.加密（含密钥加）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475//加密int AES_Encrypt(int sbx_tab[][16])&#123; int e; int plain[4][4]; int keys[4][44]; int i,j,level; printf(&quot;\\nplease input the plaintext to encryot information:&quot;); for(i=0;i&lt;4;i++) for(j=0;j&lt;4;j++) &#123; scanf(&quot;%X&quot;,&amp;e); plain[j][i]=e; &#125; getchar(); KeyExpansion(sbx_tab,keys); printf(&quot;\\n*********************[1]************************\\n&quot;); printf(&quot;Start of [1] round:\\n&quot;); for(i=0;i&lt;4;i++)&#123; for(j=0;j&lt;4;j++)&#123; plain[i][j]^=keys[i][j]; printf(&quot;%x &quot;,plain[i][j]); &#125; printf(&quot;\\n&quot;); &#125; printf(&quot;the Key of [1] round:\\n&quot;); for(i=0;i&lt;4;i++)&#123; for(j=0;j&lt;4;j++)&#123; printf(&quot;%x &quot;,keys[i][j]); &#125; printf(&quot;\\n&quot;); &#125; for(level=1;level&lt;10;level++) &#123; printf(&quot;the SubByte of [%d] round:\\n&quot;,level); SubByte(sbx_tab,plain); printf(&quot;the ShiftRow of [%d] round:\\n&quot;,level); ShiftRow(plain); printf(&quot;the MixColumn of [%d] round:\\n&quot;,level); MixColumn(plain); printf(&quot;\\n&quot;); printf(&quot;*********************[%d]************************\\n&quot;,level+1); printf(&quot;start of [%d] round:\\n&quot;,level+1); for(i=0;i&lt;4;i++)&#123; for(j=0;j&lt;4;j++)&#123; plain[i][j]^=keys[i][level*4+j]; printf(&quot;%x &quot;,plain[i][j]); &#125; printf(&quot;\\n&quot;); &#125; printf(&quot;the Keys of [%d] round is:\\n&quot;,level+1); for(i=0;i&lt;4;i++)&#123; for(j=0;j&lt;4;j++)&#123; printf(&quot;%x &quot;,keys[i][level*4+j]); &#125; printf(&quot;\\n&quot;); &#125; &#125; printf(&quot;the SubByte of [10] round:\\n&quot;); SubByte(sbx_tab,plain);//第十轮循环，注意第十轮加密没有进行列混淆 printf(&quot;the ShiftRow of [10] round:\\n&quot;); ShiftRow(plain); for(i=0;i&lt;4;i++) for(j=0;j&lt;4;j++) plain[i][j]^=keys[i][40+j]; printf(&quot;*******************************************\\n&quot;); printf(&quot;the ciphertext is:\\n&quot;); for(i=0;i&lt;4;i++)&#123; for(j=0;j&lt;4;j++) printf(&quot;%x &quot;, plain[i][j]); printf(&quot;\\n&quot;); &#125; return 0;&#125; 6.运行加密（并打印S盒）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354int main()&#123; int pow_tab[256]; int log_tab[256]; int mid_tab[256]; int sbx_tab[256]; int b[8]=&#123;0xf1,0xe3,0xc7,0x8f,0x1f,0x3e,0x7c,0xf8&#125;; int i,j,k,p; //S盒生成 for(i=0,p=1;i&lt;256;i++) &#123; pow_tab[i]=p; log_tab[p]=i; p=p^(p&lt;&lt;1)^(p&amp;0x80?0x11b:0); &#125; for(i=0;i&lt;256;i++) mid_tab[i]=(i?pow_tab[255-log_tab[i]]:0); for(i=0;i&lt;256;i++) &#123; int t=0,m=0,mid=0,tab=0; for(j=0;j&lt;8;j++) &#123; m=mid=(b[j]&amp;mid_tab[i]); for(k=0;k&lt;8;k++) &#123; int n=(mid&gt;&gt;1); if(m!=(n&lt;&lt;1)) t++; mid=n; m=mid; &#125; if(t%2&gt;0) &#123; int temp=1; for(k=0;k&lt;j;k++) temp=temp&lt;&lt;1; tab+=temp; &#125; t=0; &#125; sbx_tab[i]=tab^0x63; &#125; printf(&quot;***********AES_Encipher***********\\n&quot;); printf(&quot;the S_Box is:&quot;); for(i=0;i&lt;256;i++) &#123; if((i+16)%16==0)printf(&quot;\\n&quot;); printf(&quot;%X &quot;,sbx_tab[i]); &#125; //将sbx_tab放入Temp_tab中去(从一维转入二维) int Temp_tab[16][16]; for(i=0;i&lt;256;i++) Temp_tab[i/16][i%16]=sbx_tab[i]; AES_Encrypt(Temp_tab);&#125; 注：每一轮的结果也是有输出的，但是这里就没有粘贴了 结果 花了3天时间，每天晚上2个小时，再加上一个下午3个小时，终于弄完了，希望对大家有用。","categories":[{"name":"school work","slug":"school-work","permalink":"http://AndyQianq.github.io/categories/school-work/"}],"tags":[{"name":"cryptology","slug":"cryptology","permalink":"http://AndyQianq.github.io/tags/cryptology/"},{"name":"learning","slug":"learning","permalink":"http://AndyQianq.github.io/tags/learning/"}]},{"title":"东京ゴッドファーザーズ","slug":"东京教父","date":"2017-03-21T04:16:46.000Z","updated":"2018-02-23T13:02:28.681Z","comments":true,"path":"2017/03/21/东京教父/","link":"","permalink":"http://AndyQianq.github.io/2017/03/21/东京教父/","excerpt":"","text":"今天晚上才看完，真的太棒了，总之觉得这是动画电影的高峰了吧。那种暗系色调和一般的日本动画不同，它既不像宫崎骏的那样绚丽多彩，也不像新海诚那样清新温暖。那种黑色幽默夹杂在里面的感觉恰到好处，故事的情节是那么的合理而又戏剧，各种冲突和对比都在其中一一有条不紊的展现出来。 这是一部很有内涵的电影，我不得不佩服今敏的才华，曾经看过他的《千年女优》，觉得他是一个很会讲故事的人，我很敬佩会讲故事的人。每个人都有自己的故事，但是将故事说的引人入胜，这不是每个人都可以做到的，不同的人有自己不同的叙事风格。会讲故事的人，我没有在现实生活中见到过，但是很感谢在这个时代里我可以凭借我的喜好去与不同的电影，小说，画作、音乐相遇，这些美好的东西会让我觉得能在这个世界上存在真是太好了。就算自己没有什么成就，但是有生之年可以遇见自己喜欢的东西真是太好了，人类有自己的思想真是太好了。 说一说东京教父吧，不想说里面什么各种电影镜头如何如何，说一句实在的话，在棒的动画电影镜头在我看来与真正的摄像技术都是不可以比较的，动画电影的镜头可以表现摄像所不可以拍摄的东西，这也是为什么电影里面的金和花的外貌对比，人物表情可以那么的夸张，这些东西都是摄像和演员无法表现出来的，所以今敏在人物的设定上是不可复制的。 其次就是想说，动画电影里面的色彩无论多么的写实都是无法和现实的摄像相媲美的，正是因为如此，今敏巧妙的避开了这一弱势。《东京教父》中的色调是黑暗系的，人物大多也是扭曲变形的（当然没有病态的扭曲，但是与现实都是相差甚远的），当然这是为了配合故事中的一些黑色幽默和“乌龙”的剧情，我在看到电影的结尾之前时都是这样以为的，直到结尾花抱着清子（弃婴）从楼上缓缓坠落的，色调变得明亮起来，那一刻的阳光终于出现在了那个世界里（之前都是大量的夜晚的场景，好像那个世界没有白天一样）。电影中还特地有一幕阳光打在抛弃孩子的女人、金、美由纪的身上，好像给他们的人生里带去了阳光（电影里出现的人物都是“不完整的”都有自己的一段故事，之前他们的人生都是黑暗的），也预示着结局还是很温暖的。而正是这个镜头，我觉得是这个电影里最棒的镜头了，这是现实摄影所不可以表现出来的，那么微弱却又那么有力的阳光，不是那么明亮刺眼甚至还有一点残落的感觉，正是那种残缺中又透着坚强的美。当然这种美也是很具有日本风格的，虽然残败但是却是美到令人落泪，让人不停的在心里默念“要活下去啊”。对啊世界很残酷，但是要活下去啊，就是这么简单、心酸、而又幸福的事情——活下去啊。 就是这个镜头，美到令人窒息 还有很大镜头都很棒~ 像电影刚刚开始时 三个流浪汉发现孩子之前，底下仓库里的灯光是灰暗的 但是到孩子的镜头时，光线变成了暖黄色了 环境的渲染也很好 例如当三个流浪汉带着孩子做地铁时 地铁站的行人 发现了吗，行人都是步履匆匆，盯着自己的手机或者戴着耳机，没有人关心孩子为什么在三个衣裳褴褛的流浪汉手里。 同样的一点透视，同样的人物走位，色调上一个明亮一个昏暗。 在光线上的处理形成了鲜明的对比 这里的暖色灯光在昏暗中显得更加温柔 这两个场景的衔接只有短短的几秒，就把观众从女孩痛苦的回忆带到了现实。 一点也不突兀，反而自然的交代了女孩为什么离家出走，以及金和花已经在美由纪的心中成为了父亲和母亲的代替品了。 然后说电影就不可以绕开这部电影的人物和故事脉络了，但是我说过今敏是一个会讲故事的人，我在这里拙劣的将我所看到的东西一一列举就好像是把导演精心搭建好的积木城堡拆开后一一陈列在桌面上一样毫无美感可言，如果你想看这部电影，那就请你不要看下文了，这样的剧透我自己都觉得羞愧，但是如果你急于知道剧情就请继续看下去吧。 我刚刚说过电影里每一个人都有自己的故事，不仅仅是主要人物金、花，美由纪，还包括金在路上遇见的老人、抛弃孩子的男人和女人、金的女儿和医生、总是遇见的司机先生…… 同时主要人物都有自己的不同的背景，花曾经变性在歌厅唱歌，与自己爱的人私奔后爱人先于自己去世，自己一蹶不振而流浪。金曾经经营着自行车店但是沉迷于赌博抛妻弃女，最后自己羞愧难堪而离家流浪。美由纪觉得在家中体会不到爱处理不好与父亲和继母的关系，在父亲丢掉自己捡回来的猫后捅了父亲一刀，离家出走去流浪。 虽然三个人流浪的原因各不相同，但是在遇见被抛弃的孩子之前他们三个就已经在一起生活了，而电影故事的开始也正是放在三个人在垃圾堆中捡到孩子时。那么自然按照一般电影的套路，自然这三个流浪汉要将孩子送回到亲身父母的身边。这也是电影的主线剧情，但是我觉得电影并不是像宝贝计划那样只是简单的讲述送孩子回去的路上发生的事情，而是通过送孩子回家的路上遇见的人、事将三个流浪汉相遇之前的生活娓娓道来。 电影中有太多的戏剧性的情节，导演将这些情节合理化的手法是十分巧妙的，同时还要保证剧情的连贯性这才是电影最大的妙处。更厉害的是导演不仅将所有的情节连贯，还在处处充满着世界温柔的一面。你可以在路人僵硬的表情中感受到那个世界的孤独，可以从火车上人们对流浪汉嫌恶地将口鼻捂住看到那个世界的无情，可以从形形色色的小配角像家庭破碎的抛弃孩子的男人和女人、市侩的邻居大妈、寒夜中将金打的不省人事的人渣看到这个世界的残酷。但是在残酷之中导演赋予着温暖，金就算是债台高筑被债主逼得无家可归但是还是在债主被枪射伤后关心地说着“大丈夫”，在得知债主安然无恙后舒心的说了已经“よかったね”。这样善良的金果然生活也不忍心对他残酷吧，所以就算金抛妻弃女但是还是被自己的女儿原谅了，虽然失去了工作，但是他善良的秉性让他救了一位垂危的老人，老人临死前给他的东西在故事的结尾也通过一个镜头说明了那是一个中了两个亿的彩票。老人们常说“善有善报”，而现在我们可能跟喜欢说“他被这个世界温柔对待了吧~” 美由纪也是，虽然坐着的时候喜欢像一个男人一样将腿张开，嘴上说着叛逆的话，但是其实只是一种对自己本能的保护吧。女孩还在家里的时候，体型臃肿，应该是那种青春期中学校里不受欢迎有一点自闭的孩子吧，所以本能的像一个刺猬一样。因为自闭，因为缺少和父母的交流而变得更加古怪起来。她不知道怎样变得受欢迎起来，不知道怎样向父母所爱，也不知道怎样爱别人，所以将所有的感情都寄托在了一只流浪猫上，所以在流浪猫被父亲丢掉后，彻底的不能接受了，将父亲捅伤后离家了。虽然女孩的例子有一些极端了，但是我觉得每个人总能在她的身上或多或少的看见自己的影子，那个在青春期里不懂事的孩子，那个总是装作不在乎的表情，那个知道离家后给父亲打电话时不敢说话被憋到哭泣的表情。 导演是温柔的，所以最后孩子送回到亲生父母的身边了，美由纪被父亲原谅了不用背负着罪恶终于回到了家中了，抛弃孩子的男人和失去孩子的女人重新修复着自己破碎的家，金被女儿原谅了，花和金的故事也还在继续，也许之后他们发现两个亿的彩票后会过上富裕的生活（但是我觉得依照花的个性会逼着金把两个亿都捐掉，然后扛着金去流浪吧）。故事就这样结束了，世界很残酷但是因为有他们变得温柔了起来。 看到结尾，我很感谢温柔的今敏，感谢这个不那么美好的世界。 1：35才看完电影，看完就急急敲这篇观后感，写到这已经是晚上3：12分了。。。明天早上8点还要上课，我先睡去了。 PS：在这个电影里每个人自己的故事，每个人物都是活的，他们动画中只会讲台词的二次元人物而是每句话中都映射着自己的人生。 这个还是等到有时间了在说吧~ 有错字的请将就一下，我以后想起来会修改的~","categories":[{"name":"movies","slug":"movies","permalink":"http://AndyQianq.github.io/categories/movies/"}],"tags":[{"name":"今敏","slug":"今敏","permalink":"http://AndyQianq.github.io/tags/今敏/"}]}]}